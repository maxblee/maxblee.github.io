<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>text_data.index &#8212; Text Data 0.1.0 documentation</title>
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/katex-math.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
    <script src="../../_static/katex_autorenderer.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html">
          Text Data</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Max Lee Documentation Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_structure.html">How <code class="code docutils literal notranslate"><span class="pre">text_data</span></code> is organized</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../corpus.html">Corpus Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../exploration.html">Exploring Text Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">text_data</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>
              
            
            
              
                
              
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <h1>Source code for text_data.index</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;This module handles the indexing of `text_data`.</span>

<span class="sd">Its two classes — :code:`WordIndex` and :code:`Corpus` — form the central part</span>
<span class="sd">of this library.</span>

<span class="sd">:class:`text_data.index.WordIndex` indexes lists of documents — which themselves form</span>
<span class="sd">lists of words or phrases — and offers utilities for performing</span>
<span class="sd">statistical calculations on your data.</span>

<span class="sd">Using the index, you can find out how many times a given word appeared in a</span>
<span class="sd">document or do more complicated things, like finding the TF-IDF values</span>
<span class="sd">for every single word across all of the documents in a corpus. In addition</span>
<span class="sd">to offering a bunch of different ways to compute statistics, :code:`WordIndex`</span>
<span class="sd">also offers capabilities for creating new :code:`WordIndex` objects — something</span>
<span class="sd">that can be very helpful if you&#39;re trying to figure out what</span>
<span class="sd">makes a set of documents different from some other documents.</span>

<span class="sd">The :class:`text_data.index.Corpus`, meanwhile, is a wrapper over :code:`WordIndex` that offers tools for searching</span>
<span class="sd">through sets of documents. In addition, it offers tools for visually seeing the results of search queries.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># https://stackoverflow.com/questions/33533148/how-do-i-type-hint-a-method-with-the-type-of-the-enclosing-class</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Generator</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Set</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">text_data</span> <span class="kn">import</span> <span class="n">core</span><span class="p">,</span> <span class="n">tokenize</span>
<span class="kn">from</span> <span class="nn">text_data.query</span> <span class="kn">import</span> <span class="n">Query</span><span class="p">,</span> <span class="n">QueryItem</span>

<span class="c1">#: This represents the position of a word or phrase within a document.</span>
<span class="c1">#:</span>
<span class="c1">#: See :meth:`text_data.index.Corpus.search_occurrences` for more details and an example.</span>
<span class="c1">#:</span>
<span class="c1">#: Args:</span>
<span class="c1">#:      doc_id (int): The index of the document within the index</span>
<span class="c1">#:      first_idx (int): The index of the first word within the tokenized document at :code:`corpus.tokenized_documents[doc_id]`.</span>
<span class="c1">#:      last_idx (int): The index of the last word within the tokenized document at :code:`corpus.tokenized_documents[doc_id]`.</span>
<span class="c1">#:      raw_start (Optional[int]): The starting character-level index within the raw string document at :code:`corpus.documents[doc_id]`.</span>
<span class="c1">#:      raw_end (Optional[int]): The index after the ending character-level index within the raw string document at :code:`corpus.documents[doc_id]`.</span>
<span class="n">PositionResult</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;PositionResult&quot;</span><span class="p">,</span> <span class="s2">&quot;doc_id first_idx last_idx raw_start raw_end&quot;</span>
<span class="p">)</span>

<span class="n">SearchResult</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">PositionResult</span><span class="p">]</span>
<span class="n">CorpusClass</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;CorpusClass&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="s2">&quot;Corpus&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="WordIndex"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex">[docs]</a><span class="k">class</span> <span class="nc">WordIndex</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;An inverted, positional index containing the words in a corpus.</span>

<span class="sd">    This is designed to allow people to be able to quickly compute statistics</span>
<span class="sd">    about the language used across a corpus. The class offers a couple of broad</span>
<span class="sd">    strategies for understanding the ways in which words are used across documents.</span>

<span class="sd">    **Manipulating Indexes**</span>
<span class="sd">    These functions are designed to allow you to create new indexes based</span>
<span class="sd">    on ones you already have. They operate kind of like slices and filter</span>
<span class="sd">    functions in :code:`pandas`, where your goal is to be able to</span>
<span class="sd">    create new data structures that you can analyze independently from</span>
<span class="sd">    ones you&#39;ve already created. Most of them can also be used</span>
<span class="sd">    with method chaining. However, some of these functions remove</span>
<span class="sd">    positional information from the index, so be careful.</span>

<span class="sd">    - :meth:`~text_data.index.WordIndex.copy` creates an identical copy of a :code:`WordIndex`</span>
<span class="sd">      object.</span>
<span class="sd">    - :meth:`~text_data.index.WordIndex.slice`, :meth:`~text_data.index.WordIndex.slice_many`,</span>
<span class="sd">      and :meth:`~text_data.index.WordIndex.split_off`</span>
<span class="sd">      all take sets of document indexes and create new indexes with only those</span>
<span class="sd">      documents.</span>
<span class="sd">    - :meth:`~text_data.index.WordIndex.add_documents` allows you to add new</span>
<span class="sd">      documents into an existing :code:`WordIndex` object.</span>
<span class="sd">      :meth:`~text_data.index.WordIndex.concatenate` similarly combines</span>
<span class="sd">      :code:`WordIndex` objects into a single :code:`WordIndex`.</span>
<span class="sd">    - :meth:`~text_data.index.WordIndex.flatten` takes a :code:`WordIndex`</span>
<span class="sd">      and returns an identical index that only has one document.</span>
<span class="sd">    - :meth:`~text_data.index.WordIndex.skip_words` takes a set of words</span>
<span class="sd">      and returns a :code:`WordIndex` that does not have those words.</span>
<span class="sd">    - :meth:`~text_data.index.WordIndex.reset_index` changes the index of words.</span>

<span class="sd">    **Corpus Information**</span>

<span class="sd">    A number of functions are designed to allow you to look up information</span>
<span class="sd">    about the corpus. For instance, you can collect a sorted list</span>
<span class="sd">    or a set of all the unique words in the corpus. Or you can get a list</span>
<span class="sd">    of the most commonly appearing elements:</span>

<span class="sd">    * :attr:`~text_data.index.WordIndex.vocab` and :attr:`~text_data.index.WordIndex.vocab_list`</span>
<span class="sd">      both return the unique words or phrases appearing in the index.</span>
<span class="sd">    * :attr:`~text_data.index.WordIndex.vocab_size` gets the number of unique words in the index.</span>
<span class="sd">    * :attr:`~text_data.index.WordIndex.num_words` gets the total number of words in the index.</span>
<span class="sd">    * :attr:`~text_data.index.WordIndex.doc_lengths` gets a dictionary mapping documents to</span>
<span class="sd">      the number of tokens, or words, they contain.</span>


<span class="sd">    **Word Statistics**</span>

<span class="sd">    These allow you to gather statistics about single words</span>
<span class="sd">    or about word, document pairs. For instance, you can see</span>
<span class="sd">    how many words there are in the corpus, how many unique words there are,</span>
<span class="sd">    or how often a particular word appears in a document.</span>

<span class="sd">    The statistics generally fit into four categories.</span>
<span class="sd">    The first category computes statistics about how often a specific word appears</span>
<span class="sd">    in the corpus as a whole. The second category computes statistics</span>
<span class="sd">    about how often a specific word appears in a specific document.</span>
<span class="sd">    The third and fourth categories echo those first two categories</span>
<span class="sd">    but perform the statistics efficiently across the corpus as a whole,</span>
<span class="sd">    creating 1-dimensional numpy arrays in the case of the word-corpus</span>
<span class="sd">    statistics and 2-dimensional numpy arrays in the case of the word-document</span>
<span class="sd">    statistics. Functions in these latter two categories all end in</span>
<span class="sd">    :code:`_vector` and :code:`_matrix` respectively.</span>

<span class="sd">    Here&#39;s how those statistics map to one another:</span>

<span class="sd">    .. list-table:: Word Statistics</span>
<span class="sd">        :widths: 40 40 40 40</span>
<span class="sd">        :header-rows: 1</span>

<span class="sd">        * - Word-Corpus</span>
<span class="sd">          - Word-Document</span>
<span class="sd">          - Vector</span>
<span class="sd">          - Matrix</span>
<span class="sd">        * - :meth:`~text_data.index.WordIndex.word_count`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.term_count`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.word_count_vector`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.count_matrix`</span>
<span class="sd">        * - :meth:`~text_data.index.WordIndex.word_frequency`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.term_frequency`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.word_freq_vector`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.frequency_matrix`</span>
<span class="sd">        * - :meth:`~text_data.index.WordIndex.document_count`</span>
<span class="sd">          -</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.doc_count_vector`</span>
<span class="sd">          -</span>
<span class="sd">        * - :meth:`~text_data.index.WordIndex.document_frequency`</span>
<span class="sd">          -</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.doc_freq_vector`</span>
<span class="sd">          -</span>
<span class="sd">        * - :meth:`~text_data.index.WordIndex.idf`</span>
<span class="sd">          -</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.idf_vector`</span>
<span class="sd">          -</span>
<span class="sd">        * - :meth:`~text_data.index.WordIndex.odds_word`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.odds_document`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.odds_vector`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.odds_matrix`</span>
<span class="sd">        * - :code:`__contains__`</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.doc_contains`</span>
<span class="sd">          -</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.one_hot_matrix`</span>
<span class="sd">        * -</span>
<span class="sd">          -</span>
<span class="sd">          -</span>
<span class="sd">          - :meth:`~text_data.index.WordIndex.tfidf_matrix`</span>

<span class="sd">    In the case of the vector and matrix calculations, the arrays</span>
<span class="sd">    represent the unique words of the vocabulary,</span>
<span class="sd">    presented in sorted order. As a result, you can safely run</span>
<span class="sd">    element-wise calculations over the matrices.</span>

<span class="sd">    In addition to the term vector and term-document matrix functions, there is</span>
<span class="sd">    :meth:`~text_data.index.WordIndex.get_top_words`, which is designed</span>
<span class="sd">    to allow you to find the highest or lowest scores and their associated words along any</span>
<span class="sd">    term vector or term-document matrix you please.</span>

<span class="sd">    Note:</span>
<span class="sd">        For the most part, you will not want to instantiate :code:`WordIndex` directly.</span>
<span class="sd">        Instead, you will likely use :class:`~text_data.index.Corpus`, which subclasses</span>
<span class="sd">        :code:`WordIndex`.</span>

<span class="sd">        That&#39;s because :class:`~text_data.index.Corpus` offers utilities for searching through</span>
<span class="sd">        documents. In addition, with the help of tools from :py:mod:`text_data.tokenize`,</span>
<span class="sd">        instantiating :class:`~text_data.index.Corpus` objects is a bit simpler than</span>
<span class="sd">        instantiating :code:`WordIndex` objects directly.</span>

<span class="sd">        I particularly recommend that you **do not** instantiate the</span>
<span class="sd">        :code:`indexed_locations` directly (i.e. outside of :class:`~text_data.index.Corpus`).</span>
<span class="sd">        The only way you can do anything with :code:`indexed_locations` from outside of</span>
<span class="sd">        :class:`~text_data.index.Corpus` is by using an internal attribute</span>
<span class="sd">        and hacking through poorly documented Rust code.</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenized_documents: A list of documents where each document is a list of words.</span>
<span class="sd">        indexed_locations: A list of documents where each documents contains a list</span>
<span class="sd">            of the start end positions of the words in :code:`tokenized_documents`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenized_documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">indexed_locations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">PositionalIndex</span><span class="p">(</span><span class="n">tokenized_documents</span><span class="p">,</span> <span class="n">indexed_locations</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Determines whether the index has a given word.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span>

    <span class="c1"># Index manipulation</span>
    <span class="c1"># These functions take create new indexes based on existing ones</span>
    <span class="c1"># one of them — split_off — mutates the existing object;</span>
    <span class="c1"># the others don&#39;t</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_from_index</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">PositionalIndex</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates an index from the Rust PositionalIndex.&quot;&quot;&quot;</span>
        <span class="c1"># probably a better way to do this, but this just sets an empty data</span>
        <span class="c1"># and overrides the value of `self.index`</span>
        <span class="n">cls_item</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">([])</span>
        <span class="n">cls_item</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">index</span>
        <span class="k">return</span> <span class="n">cls_item</span>

<div class="viewcode-block" id="WordIndex.copy"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;This creates a copy of itself.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span></div>

<div class="viewcode-block" id="WordIndex.reset_index"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.reset_index">[docs]</a>    <span class="k">def</span> <span class="nf">reset_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;An in-place operation that resets the document indexes for this corpus.</span>

<span class="sd">        When you reset the index, all of the documents change their</span>
<span class="sd">        values, starting at :code:`start_idx` (and incrementing from there). For the most</span>
<span class="sd">        part, you will not need to do this, since most of the library</span>
<span class="sd">        does not give you the option to change the document indexes. However,</span>
<span class="sd">        it may be useful when you&#39;re using :meth:`~text_data.index.WordIndex.slice`</span>
<span class="sd">        or :meth:`~text_data.index.WordIndex.split_off`.</span>

<span class="sd">        Args:</span>
<span class="sd">            start_idx: The first (lowest) document index you want to set.</span>
<span class="sd">                Values must be positive. Defaults to 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">start_idx</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.concatenate"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.concatenate">[docs]</a>    <span class="k">def</span> <span class="nf">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">WordIndex</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates a :code:`WordIndex` object with the documents of both this object and the other.</span>

<span class="sd">        See :func:`text_data.multi_corpus.concatenate` for more details.</span>

<span class="sd">        Args:</span>
<span class="sd">            ignore_index: If set to :code:`True`, which is the default, the</span>
<span class="sd">                document indexes will be re-indexed starting from 0.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If :code:`ignore_index` is set to :code:`False` and some</span>
<span class="sd">                of the indexes overlap.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_index</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.add_documents"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.add_documents">[docs]</a>    <span class="k">def</span> <span class="nf">add_documents</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenized_documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">indexed_locations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This function updates the index with new documents.</span>

<span class="sd">        It operates similarly to :meth:`text_data.index.Corpus.update`,</span>
<span class="sd">        taking new documents and mutating the existing one.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; tokenized_words = [&quot;im just a simple document&quot;.split()]</span>
<span class="sd">            &gt;&gt;&gt; index = WordIndex(tokenized_words)</span>
<span class="sd">            &gt;&gt;&gt; len(index)</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; index.num_words</span>
<span class="sd">            5</span>
<span class="sd">            &gt;&gt;&gt; index.add_documents([&quot;now im an entire corpus&quot;.split()])</span>
<span class="sd">            &gt;&gt;&gt; len(index)</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; index.num_words</span>
<span class="sd">            10</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">tokenized_documents</span><span class="p">,</span> <span class="n">indexed_locations</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.skip_words"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.skip_words">[docs]</a>    <span class="k">def</span> <span class="nf">skip_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates a :code:`WordIndex` without any of the skipped words.</span>

<span class="sd">        This enables you to create an index that does not contain rare</span>
<span class="sd">        words, for example. The index will not have any positions</span>
<span class="sd">        associated with them, so be careful when implementing</span>
<span class="sd">        it on a :class:`text_data.index.Corpus` object.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; skip_words = {&quot;document&quot;}</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;document&quot;])</span>
<span class="sd">            &gt;&gt;&gt; &quot;document&quot; in corpus</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt; without_document = corpus.skip_words(skip_words)</span>
<span class="sd">            &gt;&gt;&gt; &quot;document&quot; in without_document</span>
<span class="sd">            False</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">skip_words</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_index</span><span class="p">(</span><span class="n">index</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.flatten"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.flatten">[docs]</a>    <span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Flattens a multi-document index into a single-document corpus.</span>

<span class="sd">        This creates a new :code:`WordIndex` object stripped of any positional</span>
<span class="sd">        information that has a single document in it. However, the list of words</span>
<span class="sd">        and their indexes remain.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;i am a document&quot;, &quot;so am i&quot;])</span>
<span class="sd">            &gt;&gt;&gt; len(corpus)</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; flattened = corpus.flatten()</span>
<span class="sd">            &gt;&gt;&gt; len(flattened)</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; assert corpus.most_common() == flattened.most_common()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_index</span><span class="p">(</span><span class="n">index</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.slice"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.slice">[docs]</a>    <span class="k">def</span> <span class="nf">slice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indexes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns an index that just contains documents from the set of words.</span>

<span class="sd">        Args:</span>
<span class="sd">            indexes: A set of index values for the documents.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; index = WordIndex([[&quot;example&quot;], [&quot;document&quot;], [&quot;another&quot;], [&quot;example&quot;]])</span>
<span class="sd">            &gt;&gt;&gt; sliced_idx = index.slice({0, 2})</span>
<span class="sd">            &gt;&gt;&gt; len(sliced_idx)</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; sliced_idx.most_common()</span>
<span class="sd">            [(&#39;another&#39;, 1), (&#39;example&#39;, 1)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">indexes</span><span class="p">))</span></div>

<div class="viewcode-block" id="WordIndex.split_off"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.split_off">[docs]</a>    <span class="k">def</span> <span class="nf">split_off</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indexes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns an index with just a set of documents, while removing them from the index.</span>

<span class="sd">        Args:</span>
<span class="sd">            indexes: A set of index values for the documents.</span>

<span class="sd">        Note:</span>
<span class="sd">            This removes words from the index inplace. So be make sure you</span>
<span class="sd">            want to do that before using this function.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; index = WordIndex([[&quot;example&quot;], [&quot;document&quot;], [&quot;another&quot;], [&quot;example&quot;]])</span>
<span class="sd">            &gt;&gt;&gt; split_idx = index.split_off({0, 2})</span>
<span class="sd">            &gt;&gt;&gt; len(split_idx)</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; len(index)</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; split_idx.most_common()</span>
<span class="sd">            [(&#39;another&#39;, 1), (&#39;example&#39;, 1)]</span>
<span class="sd">            &gt;&gt;&gt; index.most_common()</span>
<span class="sd">            [(&#39;document&#39;, 1), (&#39;example&#39;, 1)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">split_off</span><span class="p">(</span><span class="n">indexes</span><span class="p">))</span></div>

<div class="viewcode-block" id="WordIndex.slice_many"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.slice_many">[docs]</a>    <span class="k">def</span> <span class="nf">slice_many</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indexes_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">WordIndex</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;This operates like :meth:`~text_data.index.WordIndex.slice` but creates multiple :class:`~text_data.index.WordIndex` objects.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;another example&quot;, &quot;yet another&quot;])</span>
<span class="sd">            &gt;&gt;&gt; first, second, third = corpus.slice_many([{0}, {1}, {2}])</span>
<span class="sd">            &gt;&gt;&gt; first.documents</span>
<span class="sd">            [&#39;example document&#39;]</span>
<span class="sd">            &gt;&gt;&gt; second.documents</span>
<span class="sd">            [&#39;another example&#39;]</span>
<span class="sd">            &gt;&gt;&gt; third.documents</span>
<span class="sd">            [&#39;yet another&#39;]</span>

<span class="sd">        Args:</span>
<span class="sd">            indexes_list: A list of sets of indexes. See :meth:`text_data.index.WordIndex.slice` for details.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span> <span class="k">for</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="n">indexes_list</span><span class="p">]</span></div>

    <span class="c1"># Corpus Information</span>
    <span class="c1"># This section returns simple information about a corpus — how many</span>
    <span class="c1"># words are there, what the vocabulary is, etc.</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns all of the unique words in the index.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;a cat and a dog&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.vocab == {&quot;a&quot;, &quot;cat&quot;, &quot;and&quot;, &quot;dog&quot;}</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a sorted list of the words appearing in the index.</span>

<span class="sd">        This is primarily intended for use in matrix or vector functions,</span>
<span class="sd">        where the order of the words matters.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;a cat and a dog&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.vocab_list</span>
<span class="sd">            [&#39;a&#39;, &#39;and&#39;, &#39;cat&#39;, &#39;dog&#39;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">vocabulary_list</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the total number of unique words in the corpus.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;a cat and a dog&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.vocab_size</span>
<span class="sd">            4</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_words</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the total number of words in the corpus (not just unique).</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;a cat and a dog&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.num_words</span>
<span class="sd">            5</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">num_words</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">doc_lengths</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a dictionary mapping the document indices to their lengths.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;a cat and a dog&quot;, &quot;a cat&quot;, &quot;&quot;])</span>
<span class="sd">            &gt;&gt;&gt; assert corpus.doc_lengths == {0: 5, 1: 2, 2: 0}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">doc_lengths</span>

    <span class="c1"># Point Estimates</span>
    <span class="c1"># This section contains point estimates for the index. This includes</span>
    <span class="c1"># statistics related to how often words appear in a particular document,</span>
    <span class="c1"># how often words appear across the corpus, etc.</span>
    <span class="c1">#</span>
    <span class="c1"># Word Statistics</span>
    <span class="c1"># These provide statistics about specific words, without</span>
    <span class="c1"># requiring any information about the documents.</span>

<div class="viewcode-block" id="WordIndex.document_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.document_count">[docs]</a>    <span class="k">def</span> <span class="nf">document_count</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the total number of documents a word appears in.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.document_count(&quot;example&quot;)</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; corpus.document_count(&quot;another&quot;)</span>
<span class="sd">            1</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">document_count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.document_frequency"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.document_frequency">[docs]</a>    <span class="k">def</span> <span class="nf">document_frequency</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the percentage of documents that contain a word.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.document_frequency(&quot;example&quot;)</span>
<span class="sd">            1.0</span>
<span class="sd">            &gt;&gt;&gt; corpus.document_frequency(&quot;another&quot;)</span>
<span class="sd">            0.5</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">document_frequency</span><span class="p">(</span><span class="n">word</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.idf"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.idf">[docs]</a>    <span class="k">def</span> <span class="nf">idf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the inverse document frequency.</span>

<span class="sd">        If the number of documents in your :code:`WordIndex`</span>
<span class="sd">        :code:`index` is :math:`N` and the document frequency from</span>
<span class="sd">        :meth:`~text_data.index.WordIndex.document_frequency` is</span>
<span class="sd">        :math:`df`, the inverse document frequency is :math:`\frac{N}{df}`.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.idf(&quot;example&quot;)</span>
<span class="sd">            1.0</span>
<span class="sd">            &gt;&gt;&gt; corpus.idf(&quot;another&quot;)</span>
<span class="sd">            2.0</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking for.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">idf</span><span class="p">(</span><span class="n">word</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.docs_with_word"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.docs_with_word">[docs]</a>    <span class="k">def</span> <span class="nf">docs_with_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a list of all the documents containing a word.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;another document&quot;])</span>
<span class="sd">            &gt;&gt;&gt; assert corpus.docs_with_word(&quot;document&quot;) == {0, 1}</span>
<span class="sd">            &gt;&gt;&gt; assert corpus.docs_with_word(&quot;another&quot;) == {1}</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">docs_with_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.word_counter"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.word_counter">[docs]</a>    <span class="k">def</span> <span class="nf">word_counter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Maps the documents containing a word to the number of times the word appeared.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;a bird&quot;, &quot;a bird and a plane&quot;, &quot;two birds&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.word_counter(&quot;a&quot;) == {0: 1, 1: 2}</span>
<span class="sd">            True</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary mapping the document index of the word to the number of times</span>
<span class="sd">                it appeared in that document.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">word_counter</span><span class="p">(</span><span class="n">word</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.most_common"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.most_common">[docs]</a>    <span class="k">def</span> <span class="nf">most_common</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_words</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the most common items.</span>

<span class="sd">        This is nearly identical to :code:`collections.Counter.most_common`.</span>
<span class="sd">        However, unlike `collections.Counter.most_common`, the values that</span>
<span class="sd">        are returned appear in alphabetical order.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;i walked to the zoo&quot;, &quot;i bought a zoo&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.most_common()</span>
<span class="sd">            [(&#39;i&#39;, 2), (&#39;zoo&#39;, 2), (&#39;a&#39;, 1), (&#39;bought&#39;, 1), (&#39;the&#39;, 1), (&#39;to&#39;, 1), (&#39;walked&#39;, 1)]</span>
<span class="sd">            &gt;&gt;&gt; corpus.most_common(2)</span>
<span class="sd">            [(&#39;i&#39;, 2), (&#39;zoo&#39;, 2)]</span>

<span class="sd">        Args:</span>
<span class="sd">            num_words: The number of words you return. If you enter None</span>
<span class="sd">                or you enter a number larger than the total number of words,</span>
<span class="sd">                it returns all of the words, in sorted order from most common to least common.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">num_words</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.max_word_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.max_word_count">[docs]</a>    <span class="k">def</span> <span class="nf">max_word_count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the most common word and the number of times it appeared in the corpus.</span>

<span class="sd">        Returns :code:`None` if there are no words in the corpus.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([])</span>
<span class="sd">            &gt;&gt;&gt; corpus.max_word_count() is None</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt; corpus.update([&quot;a bird a plane superman&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.max_word_count()</span>
<span class="sd">            (&#39;a&#39;, 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">max_word_count</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.word_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.word_count">[docs]</a>    <span class="k">def</span> <span class="nf">word_count</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the total number of times the word appeared.</span>

<span class="sd">        Defaults to 0 if the word never appeared.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;this is a document&quot;, &quot;a bird and a plane&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.word_count(&quot;document&quot;)</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; corpus.word_count(&quot;a&quot;)</span>
<span class="sd">            3</span>
<span class="sd">            &gt;&gt;&gt; corpus.word_count(&quot;malarkey&quot;)</span>
<span class="sd">            0</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The string word (or phrase).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">word_count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.word_frequency"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.word_frequency">[docs]</a>    <span class="k">def</span> <span class="nf">word_frequency</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the frequency in which the word appeared in the corpus.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;this is fun&quot;, &quot;or is it&quot;])</span>
<span class="sd">            &gt;&gt;&gt; np.isclose(corpus.word_frequency(&quot;fun&quot;), 1. / 6.)</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt; np.isclose(corpus.word_frequency(&quot;is&quot;), 2. / 6.)</span>
<span class="sd">            True</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The string word or phrase.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">word_frequency</span><span class="p">(</span><span class="n">word</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.odds_word"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.odds_word">[docs]</a>    <span class="k">def</span> <span class="nf">odds_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">sublinear</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the odds of seeing a word at random.</span>

<span class="sd">        In statistics, the *odds* of something happening are the probability</span>
<span class="sd">        of it happening, versus the probability of it not happening,</span>
<span class="sd">        that is :math:`\frac{p}{1 - p}`. The &quot;log odds&quot; of</span>
<span class="sd">        something happening — the result of using :code:`self.log_odds_word` —</span>
<span class="sd">        is similarly equivalent to :math:`log_{2}{\frac{p}{1 - p}}`.</span>

<span class="sd">        (The probability in this case is simply the word frequency.)</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;i like odds ratios&quot;])</span>
<span class="sd">            &gt;&gt;&gt; np.isclose(corpus.odds_word(&quot;odds&quot;), 1. / 3.)</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt; np.isclose(corpus.odds_word(&quot;odds&quot;, sublinear=True), np.log2(1./3.))</span>
<span class="sd">            True</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up.</span>
<span class="sd">            sublinear: If true, returns the</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">odds_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">sublinear</span><span class="p">)</span></div>

    <span class="c1"># Word-Document Statistics</span>
    <span class="c1">#</span>
    <span class="c1">#   These provide statistics about words within a particular document.</span>
<div class="viewcode-block" id="WordIndex.doc_contains"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.doc_contains">[docs]</a>    <span class="k">def</span> <span class="nf">doc_contains</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;States whether the given document contains the word.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;words&quot;, &quot;more words&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.doc_contains(&quot;more&quot;, 0)</span>
<span class="sd">            False</span>
<span class="sd">            &gt;&gt;&gt; corpus.doc_contains(&quot;more&quot;, 1)</span>
<span class="sd">            True</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up.</span>
<span class="sd">            document: The index of the document.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the document you&#39;re looking up doesn&#39;t exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">doc_contains</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">document</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.term_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.term_count">[docs]</a>    <span class="k">def</span> <span class="nf">term_count</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the total number of times a word appeared in a document.</span>

<span class="sd">        Assuming the document exists, returns 0 if the word does not</span>
<span class="sd">        appear in the document.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;i am just thinking random thoughts&quot;, &quot;am i&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.term_count(&quot;random&quot;, 0)</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; corpus.term_count(&quot;random&quot;, 1)</span>
<span class="sd">            0</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up.</span>
<span class="sd">            document: The index of the document.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If you selected a document</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">term_count</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">document</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.term_frequency"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.term_frequency">[docs]</a>    <span class="k">def</span> <span class="nf">term_frequency</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the proportion of words in document :code:`document` that are :code:`word`.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;just coming up with words&quot;, &quot;more words&quot;])</span>
<span class="sd">            &gt;&gt;&gt; np.isclose(corpus.term_frequency(&quot;words&quot;, 1), 0.5)</span>
<span class="sd">            True</span>
<span class="sd">            &gt;&gt;&gt; np.isclose(corpus.term_frequency(&quot;words&quot;, 0), 0.2)</span>
<span class="sd">            True</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up</span>
<span class="sd">            document: The index of the document</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the document you&#39;re looking up doesn&#39;t exist</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">term_frequency</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">document</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.odds_document"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.odds_document">[docs]</a>    <span class="k">def</span> <span class="nf">odds_document</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">sublinear</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the odds of finding a word in a document.</span>

<span class="sd">        This is the equivalent of :meth:`~text_data.index.WordIndex.odds_word`.</span>
<span class="sd">        But insteasd of calculating items at the word-corpus level, the calculations</span>
<span class="sd">        are performed at the word-document level.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;this is a document&quot;, &quot;document two&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.odds_document(&quot;document&quot;, 1)</span>
<span class="sd">            1.0</span>
<span class="sd">            &gt;&gt;&gt; corpus.odds_document(&quot;document&quot;, 1, sublinear=True)</span>
<span class="sd">            0.0</span>

<span class="sd">        Args:</span>
<span class="sd">            word: The word you&#39;re looking up</span>
<span class="sd">            document: The index of the document</span>
<span class="sd">            sublinear: If :code:`True`, returns the log-odds of finding the word in the document.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the document doesn&#39;t exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">odds_document</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">document</span><span class="p">,</span> <span class="n">sublinear</span><span class="p">)</span></div>

    <span class="c1"># Vector computations</span>
    <span class="c1">#</span>
    <span class="c1"># All of the functions in this grouping return term-vectors where each</span>
    <span class="c1"># item in the vector refers to a word in the vocabulary (returned by</span>
    <span class="c1"># `self.vocab_list`. Because this is internally stored</span>
    <span class="c1"># as a BTreeMap, these words appear in sorted order.)</span>

<div class="viewcode-block" id="WordIndex.doc_count_vector"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.doc_count_vector">[docs]</a>    <span class="k">def</span> <span class="nf">doc_count_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the total number of documents each word appears in.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.doc_count_vector()</span>
<span class="sd">            array([1., 2.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">doc_count_vector</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.doc_freq_vector"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.doc_freq_vector">[docs]</a>    <span class="k">def</span> <span class="nf">doc_freq_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the proportion of documents each word appears in.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.doc_freq_vector()</span>
<span class="sd">            array([0.5, 1. ])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">doc_freq_vector</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.idf_vector"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.idf_vector">[docs]</a>    <span class="k">def</span> <span class="nf">idf_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the inverse document frequency vector.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.idf_vector()</span>
<span class="sd">            array([2., 1.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">idf_vector</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.word_count_vector"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.word_count_vector">[docs]</a>    <span class="k">def</span> <span class="nf">word_count_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the total number of times each word appeared in the corpus.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;this example is another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.word_count_vector()</span>
<span class="sd">            array([1., 3., 1., 1.])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">word_count_vector</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.word_freq_vector"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.word_freq_vector">[docs]</a>    <span class="k">def</span> <span class="nf">word_freq_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the frequency in which each word appears over the corpus.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;this example is another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.word_freq_vector()</span>
<span class="sd">            array([0.16666667, 0.5       , 0.16666667, 0.16666667])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">word_freq_vector</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.odds_vector"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.odds_vector">[docs]</a>    <span class="k">def</span> <span class="nf">odds_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sublinear</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a vector of the odds of each word appearing at random.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;this example is another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.odds_vector()</span>
<span class="sd">            array([0.2, 1. , 0.2, 0.2])</span>
<span class="sd">            &gt;&gt;&gt; corpus.odds_vector(sublinear=True)</span>
<span class="sd">            array([-2.32192809,  0.        , -2.32192809, -2.32192809])</span>

<span class="sd">        Args:</span>
<span class="sd">            sublinear: If true, returns the log odds.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">odds_vector</span><span class="p">(</span><span class="n">sublinear</span><span class="p">)</span></div>

    <span class="c1"># Matrix statistics</span>
    <span class="c1"># All of these functions create term-document matrix statistics</span>

<div class="viewcode-block" id="WordIndex.count_matrix"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.count_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">count_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a matrix showing the number of times each word appeared in each document.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;this example is another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.count_matrix().tolist() == [[0., 1.], [1., 2.], [0., 1.], [0., 1.]]</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">count_matrix</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.frequency_matrix"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.frequency_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">frequency_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a matrix showing the frequency of each word appearing in each document.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;this example is another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.frequency_matrix().tolist() == [[0.0, 0.2], [1.0, 0.4], [0.0, 0.2], [0.0, 0.2]]</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># tf_matrix defaults to sublinear=True, normalize=False which are good settings</span>
        <span class="c1"># for computing TF-IDF. But with the opposite of those, we get the raw counts / the doc lengths</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tf_matrix</span><span class="p">(</span><span class="n">sublinear</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.one_hot_matrix"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.one_hot_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">one_hot_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a matrix showing whether each given word appeared in each document.</span>

<span class="sd">        For these matrices, all cells contain a floating point value of either a</span>
<span class="sd">        1., if the word is in that document, or a 0. if the word is not in the document.</span>

<span class="sd">        These are sometimes referred to as &#39;one-hot encoding matrices&#39; in machine learning.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example&quot;, &quot;this example is another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; np.array_equal(</span>
<span class="sd">            ...     corpus.one_hot_matrix(),</span>
<span class="sd">            ...     np.array([[0., 1.], [1., 1.], [0., 1.], [0., 1.]])</span>
<span class="sd">            ... )</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">one_hot_matrix</span><span class="p">()</span></div>

<div class="viewcode-block" id="WordIndex.odds_matrix"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.odds_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">odds_matrix</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">sublinear</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">add_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the odds of finding a word in a document for every possible word-document pair.</span>

<span class="sd">        Because not all words are likely to appear in all of the documents,</span>
<span class="sd">        this implementation adds :code:`1` to all of the numerators before taking the</span>
<span class="sd">        frequencies. So</span>

<span class="sd">        :math:`O(w) = \frac{c_{i} + 1}{N + \vert V \vert}`</span>

<span class="sd">        where :math:`\vert V \vert` is the total number of unique words in each document,</span>
<span class="sd">        :math:`N` is the total number of total words in each document, and :math:`c_i`</span>
<span class="sd">        is the count of a word in a document.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;another example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.odds_matrix()</span>
<span class="sd">            array([[0.33333333, 1.        ],</span>
<span class="sd">                   [1.        , 0.33333333],</span>
<span class="sd">                   [1.        , 1.        ]])</span>
<span class="sd">            &gt;&gt;&gt; corpus.odds_matrix(sublinear=True)</span>
<span class="sd">            array([[-1.5849625,  0.       ],</span>
<span class="sd">                   [ 0.       , -1.5849625],</span>
<span class="sd">                   [ 0.       ,  0.       ]])</span>

<span class="sd">        Args:</span>
<span class="sd">            sublinear: If :code:`True`, computes the log-odds.</span>
<span class="sd">            add_k: This adds :code:`k` to each of the non-zero elements in the matrix.</span>
<span class="sd">                Since :math:`\log{1} = 0`, this prevents 50 percent probabilities</span>
<span class="sd">                from appearing to be the same as elements that don&#39;t exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">count_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_matrix</span><span class="p">()</span>
        <span class="c1"># find the number of unique words to add 1/|V| to each probability</span>
        <span class="c1"># to avoid divide by zero problems</span>
        <span class="n">num_unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">count_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">num_words</span> <span class="o">=</span> <span class="n">count_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">nonzero_freq</span> <span class="o">=</span> <span class="p">(</span><span class="n">count_matrix</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_unique</span> <span class="o">+</span> <span class="n">num_words</span><span class="p">)</span>
        <span class="n">raw_odds</span> <span class="o">=</span> <span class="n">nonzero_freq</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">nonzero_freq</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sublinear</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">raw_odds</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">raw_odds</span></div>

<div class="viewcode-block" id="WordIndex.tfidf_matrix"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.tfidf_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">tfidf_matrix</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;l2&quot;</span><span class="p">,</span>
        <span class="n">use_idf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">smooth_idf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">sublinear_tf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">add_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;This creates a term-document TF-IDF matrix from the index.</span>

<span class="sd">        In natural language processing, TF-IDF is a mechanism for finding</span>
<span class="sd">        out which words are distinct across documents. It&#39;s used particularly</span>
<span class="sd">        widely in information retrieval, where your goal is to rank documents</span>
<span class="sd">        that you know match a query by how relevant you think they&#39;ll be.</span>

<span class="sd">        The basic intuition goes like this: If a word appears particularly</span>
<span class="sd">        frequently in a document, it&#39;s probably more relevant to that document</span>
<span class="sd">        than if the word occurred more rarely. But, some words are simply</span>
<span class="sd">        common: If document X uses the word &#39;the&#39; more often than the word</span>
<span class="sd">        &#39;idiomatic,&#39; that really tells you more about the words &#39;the&#39; and</span>
<span class="sd">        &#39;idiomatic&#39; than it does about the document.</span>

<span class="sd">        TF-IDF tries to balance these two competing interests by taking the</span>
<span class="sd">        &#39;term frequency,&#39; or how often a word appears in the document,</span>
<span class="sd">        and normalizing it by the &#39;document frequency,&#39; or the proportion</span>
<span class="sd">        of documents that contain the word. This has the effect of reducing</span>
<span class="sd">        the weights of common words (and even setting the weights of some</span>
<span class="sd">        very common words to 0 in some implementations).</span>

<span class="sd">        It should be noted that there are a number of different implementations</span>
<span class="sd">        of TF-IDF. Within information retrieval, TF-IDF is part of the `&#39;SMART</span>
<span class="sd">        Information Retrieval System&#39; &lt;https://en.wikipedia.org/wiki/SMART_Information_Retrieval_System&gt;`_.</span>
<span class="sd">        Although the exact equations can vary considerably, they typically follow the same approach:</span>
<span class="sd">        First, they find some value to represent the frequency of each word in the</span>
<span class="sd">        document. Often (but not always), this is just the raw number of times</span>
<span class="sd">        in which a word appeared in the document. Then, they normalize that</span>
<span class="sd">        based on the document frequency. And finally, they normalize</span>
<span class="sd">        those values based on the length of the document, so that long documents</span>
<span class="sd">        are not weighted more favorably (or less favorably) than shorter documents.</span>

<span class="sd">        The approach that I have taken to this is shamelessly cribbed from</span>
<span class="sd">        `scikit&#39;s TfidfTransformer &lt;https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html&gt;`_.</span>
<span class="sd">        Specifically, I&#39;ve allowed for some customization of the specific formula</span>
<span class="sd">        for TF-IDF while not including methods that require access to the raw</span>
<span class="sd">        documents, which would be computationally expensive to perform. This allows</span>
<span class="sd">        for the following options:</span>

<span class="sd">        * You can set the term frequency to either take the raw count of the word</span>
<span class="sd">          in the document (:math:`c_{t,d}`) or by using :code:`sublinear_tf=True`</span>
<span class="sd">          and taking :math:`1 + \log_{2}{c_{t,d}}`</span>
<span class="sd">        * You can skip taking the inverse document frequency :math:`df^{-1}`</span>
<span class="sd">          altogether by setting :code:`use_idf=False` or you can smooth the inverse</span>
<span class="sd">          document frequency by setting :code:`smooth_idf=True`.</span>
<span class="sd">          This adds one to the numerator and the denominator. (**Note:** Because</span>
<span class="sd">          this method is only run on a vocabulary of words that are in the corpus,</span>
<span class="sd">          there can&#39;t be any divide by zero errors, but this allows you to</span>
<span class="sd">          replicate scikit&#39;s :code:`TfidfTransformer`.)</span>
<span class="sd">        * You can add some number to the logged inverse document frequency</span>
<span class="sd">          by setting :code:`add_k` to something other than 1. This is the only</span>
<span class="sd">          difference between this implementation and scikits, as scikit automatically</span>
<span class="sd">          setts :code:`k` at 1.</span>
<span class="sd">        * Finally, you can choose how to normalize the document lengths. By default,</span>
<span class="sd">          this takes the L-2 norm, or :math:`\sqrt{\sum{w_{i,k}^{2}}}`, where :math:`w_{i,k}`</span>
<span class="sd">          is the weight you get from multiplying the term frequency by the inverse document</span>
<span class="sd">          frequency. But you can also set the norm to :code:`&#39;l1&#39;` to get the L1-norm,</span>
<span class="sd">          or :math:`\sum{\vert w_{i,k} \vert}`. Or you can set it to :code:`None` to avoid</span>
<span class="sd">          doing any document-length normalization at all.</span>

<span class="sd">        Examples:</span>
<span class="sd">            To get a sense of the different options, let&#39;s start by creating</span>
<span class="sd">            a pure count matrix with this method. To do that, we&#39;ll set</span>
<span class="sd">            :code:`norm=None` so we&#39;re not normalizing by the length of the document,</span>
<span class="sd">            :code:`use_idf=False` so we&#39;re not doing anything with the document</span>
<span class="sd">            frequency, and :code:`sublinear_tf=False` so we&#39;re not taking the</span>
<span class="sd">            logged counts:</span>

<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;a cat&quot;, &quot;a&quot;])</span>
<span class="sd">            &gt;&gt;&gt; tfidf_count_matrix = corpus.tfidf_matrix(norm=None, use_idf=False, sublinear_tf=False)</span>
<span class="sd">            &gt;&gt;&gt; assert np.array_equal(tfidf_count_matrix, corpus.count_matrix())</span>

<span class="sd">            In this particular case, setting :code:`sublinear_tf` to :code:`True`</span>
<span class="sd">            will produce the same result since all of the counts are 1 or 0</span>
<span class="sd">            and :math:`\log{1} + 1 = 1`:</span>

<span class="sd">            &gt;&gt;&gt; assert np.array_equal(corpus.tfidf_matrix(norm=None, use_idf=False), tfidf_count_matrix)</span>

<span class="sd">            Now, we can incorporate the inverse document frequency. Because the word</span>
<span class="sd">            &#39;a&#39; appears in both documents, its inverse document frequency in is 1;</span>
<span class="sd">            the inverse document frequency of &#39;cat&#39; is 2, since &#39;cat&#39; appears in half</span>
<span class="sd">            of the documents. We&#39;re additionally taking the base-2 log of the inverse document</span>
<span class="sd">            frequency and adding 1 to the final result. So we get:</span>

<span class="sd">            &gt;&gt;&gt; idf_add_1 = corpus.tfidf_matrix(norm=None, sublinear_tf=False, smooth_idf=False)</span>
<span class="sd">            &gt;&gt;&gt; assert idf_add_1.tolist() == [[1., 1.], [2.,0.]]</span>

<span class="sd">            Or we can add nothing to the logged values:</span>

<span class="sd">            &gt;&gt;&gt; idf = corpus.tfidf_matrix(norm=None, sublinear_tf=False, smooth_idf=False, add_k=0)</span>
<span class="sd">            &gt;&gt;&gt; assert idf.tolist() == [[0.0, 0.0], [1.0, 0.0]]</span>

<span class="sd">            The L-1 norm normalizes the results by the sum of the absolute values of their</span>
<span class="sd">            weights. In the case of the count matrix, this is equivalent to creating</span>
<span class="sd">            the frequency matrix:</span>

<span class="sd">            &gt;&gt;&gt; tfidf_freq_mat = corpus.tfidf_matrix(norm=&quot;l1&quot;, use_idf=False, sublinear_tf=False)</span>
<span class="sd">            &gt;&gt;&gt; assert np.array_equal(tfidf_freq_mat, corpus.frequency_matrix())</span>

<span class="sd">        Args:</span>
<span class="sd">            norm: Set to &#39;l2&#39; for the L2 norm (square root of the sums of the square weights),</span>
<span class="sd">                &#39;l1&#39; for the l1 norm (the summed absolute value, or None for no normalization).</span>
<span class="sd">            use_idf: If you set this to False, the weights will only include the term frequency</span>
<span class="sd">                (adjusted however you like)</span>
<span class="sd">            smooth_idf: Adds a constant to the numerator and the denominator.</span>
<span class="sd">            sublinear_tf: Computes the term frequency in log space.</span>
<span class="sd">            add_k: This adds k to every value in the IDF. scikit adds 1</span>
<span class="sd">                to all documents, but this allows for more variable computing</span>
<span class="sd">                (e.g. adding 0 if you want to remove words appearing in every document)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;l2&quot;</span><span class="p">,</span> <span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The norm you select must be an L1 norm, L2 norm, or None&quot;</span><span class="p">)</span>
        <span class="c1"># first compute the term frequency. Don&#39;t do any normalization yet.</span>
        <span class="n">tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tf_matrix</span><span class="p">(</span><span class="n">sublinear</span><span class="o">=</span><span class="n">sublinear_tf</span><span class="p">)</span>
        <span class="c1"># there are more elegant ways to do this, but this just ensures that</span>
        <span class="c1"># we don&#39;t compute the IDF if we don&#39;t need it</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_idf</span><span class="p">:</span>
            <span class="n">raw_idf</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="n">smooth_idf</span><span class="p">:</span>
            <span class="c1"># number of docs + 1 over document counts + 1</span>
            <span class="n">raw_idf</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">doc_count_vector</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">raw_idf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">idf_vector</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">raw_idf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># convert idf to log space and add k to all</span>
            <span class="n">idf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">raw_idf</span><span class="p">)</span> <span class="o">+</span> <span class="n">add_k</span>
            <span class="n">raw_tfidf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">idf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tf</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">raw_tfidf</span> <span class="o">=</span> <span class="n">tf</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">raw_tfidf</span>
        <span class="n">int_norm</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">norm</span> <span class="o">==</span> <span class="s2">&quot;l1&quot;</span> <span class="k">else</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">raw_tfidf</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">raw_tfidf</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="n">int_norm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordIndex.get_top_words"><a class="viewcode-back" href="../../text_data.html#text_data.index.WordIndex.get_top_words">[docs]</a>    <span class="k">def</span> <span class="nf">get_top_words</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">term_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">top_n</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">reverse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Get the top values along a term matrix.</span>

<span class="sd">        Given a matrix where each row represents a word in your vocabulary,</span>
<span class="sd">        this returns a numpy matrix of those top values, along with an array</span>
<span class="sd">        of their respective words.</span>

<span class="sd">        You can choose the number of results you want to get by setting</span>
<span class="sd">        :code:`top_n` to some positive value, or you can leave it be and return</span>
<span class="sd">        all of the results in sorted order. Additionally, by setting</span>
<span class="sd">        :code:`reverse` to False (instead of its default of :code:`True`), you can</span>
<span class="sd">        return the scores from smallest to largest.</span>

<span class="sd">        Args:</span>
<span class="sd">            term_matrix: a matrix of floats where each row represents a word</span>
<span class="sd">            top_n: The number of values you want to return. If None, returns</span>
<span class="sd">                all values.</span>
<span class="sd">            reverse: If true (the default), returns the N values with the highest scores.</span>
<span class="sd">                If false, returns the N values with the lowest scores.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple of 2-dimensional numpy arrays, where the first item</span>
<span class="sd">            is an array of the top-scoring words and the second item</span>
<span class="sd">            is an array of the top scores themselves. Both arrays</span>
<span class="sd">            are of the same size, that is :code:`min(self.vocab_size, top_n)`</span>
<span class="sd">            by the number of columns in the term matrix.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If :code:`top_n` is less than 1, if there are</span>
<span class="sd">                not the same number of rows in the matrix as there are unique</span>
<span class="sd">                words in the index, or if the numpy array doesn&#39;t have 1 or 2 dimensions.</span>

<span class="sd">        Example:</span>
<span class="sd">            The first thing you need to do in order to use this function is create</span>
<span class="sd">            a 1- or 2-dimensional term matrix, where the number of rows</span>
<span class="sd">            corresponds to the number of unique words in the corpus. Any of the</span>
<span class="sd">            functions within :code:`WordIndex` that ends in :code:`_matrix(**kwargs)`</span>
<span class="sd">            (for 2-dimensional arrays) or :code:`_vector(**kwargs)` (for 1-dimensional</span>
<span class="sd">            arrays) will do the trick here. I&#39;ll show an example with both a</span>
<span class="sd">            word count vector and a word count matrix:</span>

<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;The cat is near the birds&quot;, &quot;The birds are distressed&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.get_top_words(corpus.word_count_vector(), top_n=2)</span>
<span class="sd">            (array([&#39;the&#39;, &#39;birds&#39;], dtype=&#39;&lt;U10&#39;), array([3., 2.]))</span>
<span class="sd">            &gt;&gt;&gt; corpus.get_top_words(corpus.count_matrix(), top_n=1)</span>
<span class="sd">            (array([[&#39;the&#39;, &#39;the&#39;]], dtype=&#39;&lt;U10&#39;), array([[2., 1.]]))</span>

<span class="sd">            Similarly, you can return the scores from lowest to highest by setting :code:`reverse=False`.</span>
<span class="sd">            (This is not the default.):</span>

<span class="sd">            &gt;&gt;&gt; corpus.get_top_words(-1. * corpus.word_count_vector(), top_n=2, reverse=False)</span>
<span class="sd">            (array([&#39;the&#39;, &#39;birds&#39;], dtype=&#39;&lt;U10&#39;), array([-3., -2.]))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># https://github.com/numpy/numpy/issues/15128</span>
        <span class="c1"># this works independently of whether the array is 1-d or 2-d</span>
        <span class="n">num_rows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">term_matrix</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">top_n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">top_n</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You must enter a positive number of results you wish to return&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">num_rows</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;You must pass a term matrix (a 1- or 2-dimensional array &quot;</span>
                    <span class="s2">&quot;where every unique word is a row) to this function&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">term_matrix</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term_matrix</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must enter a 1- or 2-dimensional array&quot;</span><span class="p">)</span>
        <span class="c1"># get the sorting order of the top</span>
        <span class="n">sorted_vals</span> <span class="o">=</span> <span class="n">term_matrix</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">top_n</span> <span class="k">if</span> <span class="n">top_n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">num_rows</span>
        <span class="k">if</span> <span class="n">reverse</span><span class="p">:</span>
            <span class="n">row_slice</span><span class="p">,</span> <span class="n">ordering</span> <span class="o">=</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="n">k</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">row_slice</span><span class="p">,</span> <span class="n">ordering</span> <span class="o">=</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
        <span class="c1"># reshaping enables vectorized vocab searches; but can only do with 2-dimensional arrays</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_list</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">term_matrix</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">vocab</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">num_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># for every row, column, gets the highest ranked matches</span>
        <span class="n">top_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">term_matrix</span><span class="p">,</span> <span class="n">sorted_vals</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="n">row_slice</span><span class="p">][</span>
            <span class="n">ordering</span>
        <span class="p">]</span>
        <span class="n">top_vocab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">sorted_vals</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="n">row_slice</span><span class="p">][</span><span class="n">ordering</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">top_vocab</span><span class="p">,</span> <span class="n">top_scores</span></div></div>


<div class="viewcode-block" id="Corpus"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus">[docs]</a><span class="k">class</span> <span class="nc">Corpus</span><span class="p">(</span><span class="n">WordIndex</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;This is probably going to be your main entrypoint into :code:`text_data`.</span>

<span class="sd">    The corpus holds the raw text, the index, and the tokenized text</span>
<span class="sd">    of whatever you&#39;re trying to analyze. Its primary role is to extend</span>
<span class="sd">    the functionality of :class:`~text_data.index.WordIndex` to</span>
<span class="sd">    support searching. This means that you can use the :code:`Corpus`</span>
<span class="sd">    to search for arbitrarily long phrases using boolean search</span>
<span class="sd">    methods (AND, NOT, BUT).</span>

<span class="sd">    In addition, it allows you to add indexes so you can calculate</span>
<span class="sd">    statistics on phrases. By using :meth:`~text_data.index.Corpus.add_ngram_index`,</span>
<span class="sd">    you can figure out the frequency or TF-IDF values of multi-word</span>
<span class="sd">    phrases while still being able to search through your normal index.</span>

<span class="sd">    **Initializing Data**</span>

<span class="sd">    To instantiate the corpus, you need to include a list of documents</span>
<span class="sd">    where each document is a string of text and a tokenizer. There</span>
<span class="sd">    is a default tokenizer, which simply lowercases words and splits</span>
<span class="sd">    documents on :code:`r&quot;\w+&quot;`. For most tasks, this will be insufficient.</span>
<span class="sd">    But :py:mod:`text_data.tokenize` offers convenient ways that should</span>
<span class="sd">    make building the vast majority of tokenizers easy.</span>

<span class="sd">    The :code:`Corpus` can be instantiated using :code:`__init__` or by</span>
<span class="sd">    using :meth:`~text_data.index.Corpus.chunks`, which yields a generator,</span>
<span class="sd">    adding a mini-index. This allows you to technically perform</span>
<span class="sd">    calculations in-memory on larger databases.</span>

<span class="sd">    You can also initialize a :code:`Corpus` object by using the</span>
<span class="sd">    :meth:`~text_data.index.Corpus.slice`, :meth:`~text_data.index.Corpus.copy`,</span>
<span class="sd">    :meth:`~text_data.index.Corpus.split_off`, or :meth:`~text_data.index.Corpus.concatenate`</span>
<span class="sd">    methods. These methods work identically to their equivalent methods in</span>
<span class="sd">    :class:`text_data.index.WordIndex` while updating extra data that</span>
<span class="sd">    the corpus has, updating n-gram indexes, and automatically re-indexing the</span>
<span class="sd">    corpus.</span>

<span class="sd">    **Updating Data**</span>

<span class="sd">    There are two methods for updating or adding data to the :code:`Corpus`.</span>
<span class="sd">    :meth:`~text_data.index.Corpus.update` allows you to add new documents</span>
<span class="sd">    to the corpus. :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">    allows you to add multi-word indexes.</span>

<span class="sd">    **Searching**</span>

<span class="sd">    There are a few methods devoted to searching. :meth:`~text_data.index.Corpus.search_documents`</span>
<span class="sd">    allows you to find all of the individual documents matching a query.</span>
<span class="sd">    :meth:`~text_data.index.Corpus.search_occurrences` shows all of the individual</span>
<span class="sd">    occurrences that matched your query. :meth:`~text_data.index.Corpus.ranked_search`</span>
<span class="sd">    finds all of the individual occurrences and sorts them according to a variant</span>
<span class="sd">    of their TF-IDF score.</span>

<span class="sd">    **Statistics**</span>

<span class="sd">    Three methods allow you to get statistics about a search.</span>
<span class="sd">    :meth:`~text_data.index.Corpus.search_document_count` allows you to find</span>
<span class="sd">    the total number of documents matching your query.</span>
<span class="sd">    :meth:`~text_data.index.Corpus.search_document_freq` shows the proportion</span>
<span class="sd">    of documents matching your query. And :meth:`~text_data.index.Corpus.search_occurrence_count`</span>
<span class="sd">    finds the total number of matches you have for your query.</span>

<span class="sd">    **Display**</span>

<span class="sd">    There are a number of functions designed to help you visually see the results of your</span>
<span class="sd">    query. :meth:`~text_data.index.Corpus.display_document` and</span>
<span class="sd">    :meth:`~text_data.index.Corpus.display_documents` render your documents in HTML.</span>
<span class="sd">    :meth:`~text_data.index.Corpus.display_document_count`,</span>
<span class="sd">    :meth:`~text_data.index.Corpus.display_document_frequency`,</span>
<span class="sd">    and :meth:`~text_data.index.Corpus.display_occurrence_count`</span>
<span class="sd">    all render bar charts showing the number of query results you got.</span>
<span class="sd">    And :meth:`~text_data.index.Corpus.display_search_results` shows</span>
<span class="sd">    the result of your search.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        documents: A list of all the raw, non-tokenized documents in the corpus.</span>
<span class="sd">        tokenizer: A function that converts a list of strings (one of the documents</span>
<span class="sd">            from documents into a list of words and a list of the character-level</span>
<span class="sd">            positions where the words are located in the raw text). See :mod:`text_data.tokenize`</span>
<span class="sd">            for details.</span>
<span class="sd">        tokenized_documents: A list of the tokenized documents (each a list of words)</span>
<span class="sd">        ngram_indexes: A list of :class:`~text_data.index.WordIndex` objects</span>
<span class="sd">            for multi-word (n-gram) indexes. See :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">            for details.</span>
<span class="sd">        ngram_sep: A separator in between words. See :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">            for details.</span>
<span class="sd">        ngram_prefix: A prefix to go before any n-gram phrases. See :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">            for details.</span>
<span class="sd">        ngram_suffix: A suffix to go after any n-gram phrases. See :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">            for details.</span>

<span class="sd">    Args:</span>
<span class="sd">        documents: A list of the raw, un-tokenized texts.</span>
<span class="sd">        tokenizer: A function to tokenize the documents. See :mod:`text_data.tokenize` for details.</span>
<span class="sd">        sep: The separator you want to use for computing n-grams. See :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">            for details.</span>
<span class="sd">        prefix: The prefix you want to use for n-grams. See :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">            for details.</span>
<span class="sd">        suffix: The suffix you want to use for n-grams. See :meth:`~text_data.index.Corpus.add_ngram_index`</span>
<span class="sd">            for details.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
            <span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">TokenizeResult</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">default_tokenizer</span><span class="p">,</span>
        <span class="n">sep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">suffix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">documents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tokenized_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span>
            <span class="c1"># mypy doesn&#39;t get that this converts from a list of tuples to a tuple of lists</span>
            <span class="n">words</span><span class="p">,</span> <span class="n">positions</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">tokenized_docs</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">words</span><span class="p">,</span> <span class="n">positions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">=</span> <span class="n">words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">WordIndex</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_sep</span> <span class="o">=</span> <span class="n">sep</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_prefix</span> <span class="o">=</span> <span class="n">prefix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_suffix</span> <span class="o">=</span> <span class="n">suffix</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="p">,</span> <span class="n">positions</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

<div class="viewcode-block" id="Corpus.chunks"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.chunks">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">chunks</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">CorpusClass</span><span class="p">],</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
            <span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">TokenizeResult</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">default_tokenizer</span><span class="p">,</span>
        <span class="n">sep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">suffix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chunksize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1_000_000</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">CorpusClass</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Iterates through documents, yielding a :code:`Corpus` with :code:`chunksize` documents.</span>

<span class="sd">        This is designed to allow you to technically use :code:`Corpus` on large</span>
<span class="sd">        document sets. However, you should note that searching for documents</span>
<span class="sd">        will only work within the context of the current chunk.</span>

<span class="sd">        The same is true for any frequency metrics. As such, you should probably</span>
<span class="sd">        limit metrics to raw counts or aggregations you&#39;ve derived from raw counts.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; for docs in Corpus.chunks([&quot;chunk one&quot;, &quot;chunk two&quot;], chunksize=1):</span>
<span class="sd">            ...     print(len(docs))</span>
<span class="sd">            1</span>
<span class="sd">            1</span>

<span class="sd">        Args:</span>
<span class="sd">            documents: A list of raw text items (not tokenized)</span>
<span class="sd">            tokenizer: A function to tokenize the documents</span>
<span class="sd">            sep: The separator you want to use for computing n-grams.</span>
<span class="sd">            prefix: The prefix for n-grams.</span>
<span class="sd">            suffix: The suffix for n-grams.</span>
<span class="sd">            chunksize: The number of documents in each chunk.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">chunksize</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The chunksize must be a positive, non-zero integer.&quot;</span><span class="p">)</span>
        <span class="n">current_chunksize</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">current_document_set</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">current_chunksize</span> <span class="o">==</span> <span class="n">chunksize</span><span class="p">:</span>
                <span class="k">yield</span> <span class="bp">cls</span><span class="p">(</span><span class="n">current_document_set</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">sep</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">suffix</span><span class="p">)</span>
                <span class="n">current_document_set</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">current_chunksize</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">current_chunksize</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">current_document_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
        <span class="k">yield</span> <span class="bp">cls</span><span class="p">(</span><span class="n">current_document_set</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">sep</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">suffix</span><span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.add_ngram_index"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.add_ngram_index">[docs]</a>    <span class="k">def</span> <span class="nf">add_ngram_index</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">default</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">sep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">suffix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds an n-gram index to the corpus.</span>

<span class="sd">        This creates a :class:`~text_data.index.WordIndex` object</span>
<span class="sd">        that you can access by typing :code:`self.ngram_indexes[n]`.</span>

<span class="sd">        There are times when you might want to compute</span>
<span class="sd">        TF-IDF scores, word frequency scores or similar scores</span>
<span class="sd">        over a multi-word index. For instance, you might want to know how</span>
<span class="sd">        frequently someone said &#39;United States&#39; in a speech, without</span>
<span class="sd">        caring how often they used the word &#39;united&#39; or &#39;states&#39;.</span>

<span class="sd">        This function helps you do that. It automatically splits up your</span>
<span class="sd">        documents into an overlapping set of :code:`n`-length phrases.</span>

<span class="sd">        Internally, this takes each of your tokenized documents,</span>
<span class="sd">        merges them into lists of :code:`n`-length phrases, and joins</span>
<span class="sd">        each of those lists by a space. However, you can customize</span>
<span class="sd">        this behavior. If you set :code:`prefix`, each of the n-grams</span>
<span class="sd">        will be prefixed by that string; if you set :code:`suffix`,</span>
<span class="sd">        each of the n-grams will end with that string. And if you</span>
<span class="sd">        set :code:`sep`, each of the words in the n-gram will be separated</span>
<span class="sd">        by the separator.</span>

<span class="sd">        Example:</span>
<span class="sd">            Say you have a simple four word corpus. If you use the default</span>
<span class="sd">            settings, here&#39;s what your n-grams will look like:</span>

<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;text data is fun&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.add_ngram_index(n=2)</span>
<span class="sd">            &gt;&gt;&gt; corpus.ngram_indexes[2].vocab_list</span>
<span class="sd">            [&#39;data is&#39;, &#39;is fun&#39;, &#39;text data&#39;]</span>

<span class="sd">            By altering :code:`sep`, :code:`prefix`, or :code:`suffix`,</span>
<span class="sd">            you can alter that behavior. But, be careful to set :code:`default`</span>
<span class="sd">            to :code:`False` if you want to change the behavior</span>
<span class="sd">            from something you set up in :code:`__init__`. If you don&#39;t,</span>
<span class="sd">            this will use whatever settings you instantiated the class with.</span>

<span class="sd">            &gt;&gt;&gt; corpus.add_ngram_index(n=2, sep=&quot;&lt;/w&gt;&lt;w&gt;&quot;, prefix=&quot;&lt;w&gt;&quot;, suffix=&quot;&lt;/w&gt;&quot;, default=False)</span>
<span class="sd">            &gt;&gt;&gt; corpus.ngram_indexes[2].vocab_list</span>
<span class="sd">            [&#39;&lt;w&gt;data&lt;/w&gt;&lt;w&gt;is&lt;/w&gt;&#39;, &#39;&lt;w&gt;is&lt;/w&gt;&lt;w&gt;fun&lt;/w&gt;&#39;, &#39;&lt;w&gt;text&lt;/w&gt;&lt;w&gt;data&lt;/w&gt;&#39;]</span>

<span class="sd">        Args:</span>
<span class="sd">            n: The number of n-grams (defaults to unigrams)</span>
<span class="sd">            default: If true, will keep the values stored in init (including defaults)</span>
<span class="sd">            sep: The separator in between words (if storing n-grams)</span>
<span class="sd">            prefix: The prefix before the first word of each n-gram</span>
<span class="sd">            suffix: The suffix after the last word of each n-gram</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">default</span><span class="p">:</span>
            <span class="n">ngram_words</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">ngrams_from_documents</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="p">,</span>
                <span class="n">n</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ngram_sep</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ngram_prefix</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ngram_suffix</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ngram_words</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">ngrams_from_documents</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sep</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">suffix</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">WordIndex</span><span class="p">(</span><span class="n">ngram_words</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.add_documents"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.add_documents">[docs]</a>    <span class="k">def</span> <span class="nf">add_documents</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenized_documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">indexed_locations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This overrides the :meth:`~text_data.index.WordIndex.add_documents` method.</span>

<span class="sd">        Because :meth:`~text_data.index.Corpus` objects can have</span>
<span class="sd">        n-gram indices, simply running :code:`add_documents` would</span>
<span class="sd">        cause n-gram indices to go out of sync with the overall</span>
<span class="sd">        corpus. In order to prevent that, this function raises</span>
<span class="sd">        an error if you try to run it.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: Warns you to use :code:`~text_data.index.Corpus.update`</span>
<span class="sd">            instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;You can not use `add_documents` with a `Corpus`. Use `update` instead.&quot;</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_copy_standard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">Corpus</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This copies common information. It&#39;s internal to `copy`, `slice`, `split_off`, and `concatenate`.&quot;&quot;&quot;</span>
        <span class="n">other</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
        <span class="n">other</span><span class="o">.</span><span class="n">ngram_sep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_sep</span>
        <span class="n">other</span><span class="o">.</span><span class="n">ngram_prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_prefix</span>
        <span class="n">other</span><span class="o">.</span><span class="n">ngram_suffix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_suffix</span>

<div class="viewcode-block" id="Corpus.concatenate"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.concatenate">[docs]</a>    <span class="k">def</span> <span class="nf">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">Corpus</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Corpus</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
        <span class="sd">&quot;&quot;&quot;This combines two :code:`Corpus` objects into one, much like :meth:`text_data.index.WordIndex.concatenate`.</span>

<span class="sd">        However, the new :code:`Corpus` has data from this corpus, including n-gram data.</span>
<span class="sd">        Because of this, the two :code:`Corpus` objects must have the same keys for their</span>
<span class="sd">        n-gram dictionaries.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus_1 = Corpus([&quot;i am an example&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus_2 = Corpus([&quot;i am too&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus_1.add_ngram_index(n=2)</span>
<span class="sd">            &gt;&gt;&gt; corpus_2.add_ngram_index(n=2)</span>
<span class="sd">            &gt;&gt;&gt; combined_corpus = corpus_1.concatenate(corpus_2)</span>
<span class="sd">            &gt;&gt;&gt; combined_corpus.most_common()</span>
<span class="sd">            [(&#39;am&#39;, 2), (&#39;i&#39;, 2), (&#39;an&#39;, 1), (&#39;example&#39;, 1), (&#39;too&#39;, 1)]</span>
<span class="sd">            &gt;&gt;&gt; combined_corpus.ngram_indexes[2].most_common()</span>
<span class="sd">            [(&#39;i am&#39;, 2), (&#39;am an&#39;, 1), (&#39;am too&#39;, 1), (&#39;an example&#39;, 1)]</span>

<span class="sd">        Args:</span>
<span class="sd">            other: another :code:`Corpus` object with the same ngram indexes.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if the n-gram indexes between the two corpuses are not the same.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_corpus</span> <span class="o">=</span> <span class="n">Corpus</span><span class="p">([])</span>
        <span class="n">new_corpus</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_copy_standard</span><span class="p">(</span><span class="n">new_corpus</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_corpus</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
        <span class="n">new_corpus</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">documents</span>
        <span class="n">new_corpus</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">tokenized_documents</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">new_corpus</span></div>

<div class="viewcode-block" id="Corpus.to_index"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.to_index">[docs]</a>    <span class="k">def</span> <span class="nf">to_index</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Converts a :class:`~text_data.index.Corpus` object into a :class:`~text_data.index.WordIndex` object.</span>

<span class="sd">        :class:`~text_data.index.Corpus` objects are convenient because they allow</span>
<span class="sd">        you to search across documents, in addition to computing statistics about them.</span>
<span class="sd">        But sometimes, you don&#39;t need that, and the added convenience comes with extra</span>
<span class="sd">        memory requirements.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">WordIndex</span><span class="o">.</span><span class="n">_from_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.copy"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Corpus</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;This creates a shallow copy of a :class:`Corpus` object.</span>

<span class="sd">        It extends the contents of :class:`Corpus` to also store data about</span>
<span class="sd">        the objects themselves.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_index</span> <span class="o">=</span> <span class="n">Corpus</span><span class="p">([])</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">new_index</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">ngram_indexes</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">n</span><span class="p">:</span> <span class="n">index</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_copy_standard</span><span class="p">(</span><span class="n">new_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_index</span></div>

<div class="viewcode-block" id="Corpus.slice"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.slice">[docs]</a>    <span class="k">def</span> <span class="nf">slice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indexes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Corpus</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;This creates a :code:`Corpus` object only including the documents listed.</span>

<span class="sd">        This overrides the method in :meth:`text_data.index.WordIndex`, which</span>
<span class="sd">        does the same thing (but without making changes to the underlying document set).</span>
<span class="sd">        This also creates slices of any of the n-gram indexes you have created.</span>

<span class="sd">        Note:</span>
<span class="sd">            This also changes the indexes for the new corpus so they all go from</span>
<span class="sd">            0 to :code:`len(indexes)`.</span>

<span class="sd">        Args:</span>
<span class="sd">            indexes: A set of document indexes you want to have in the new index.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;example document&quot;, &quot;another example&quot;, &quot;yet another&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.add_ngram_index(n=2)</span>
<span class="sd">            &gt;&gt;&gt; sliced_corpus = corpus.slice({1})</span>
<span class="sd">            &gt;&gt;&gt; len(sliced_corpus)</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; sliced_corpus.most_common()</span>
<span class="sd">            [(&#39;another&#39;, 1), (&#39;example&#39;, 1)]</span>
<span class="sd">            &gt;&gt;&gt; sliced_corpus.ngram_indexes[2].most_common()</span>
<span class="sd">            [(&#39;another example&#39;, 1)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_index</span> <span class="o">=</span> <span class="n">Corpus</span><span class="p">([])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_copy_standard</span><span class="p">(</span><span class="n">new_index</span><span class="p">)</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_index</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
            <span class="n">new_index</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
        <span class="n">documents</span><span class="p">,</span> <span class="n">tokenized_docs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">sorted_indexes</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sorted_indexes</span><span class="p">:</span>
            <span class="n">documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">tokenized_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">documents</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">=</span> <span class="n">tokenized_docs</span>
        <span class="k">return</span> <span class="n">new_index</span></div>

<div class="viewcode-block" id="Corpus.split_off"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.split_off">[docs]</a>    <span class="k">def</span> <span class="nf">split_off</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indexes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Corpus</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;This operates like :meth:`~text_data.index.WordIndex.split_off`.</span>

<span class="sd">        But it additionally maintains the state of the :class:`Corpus` data,</span>
<span class="sd">        similar to how :meth:`~text_data.index.Corpus.slice` works.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;i am an example&quot;, &quot;so am i&quot;])</span>
<span class="sd">            &gt;&gt;&gt; sliced_data = corpus.split_off({0})</span>
<span class="sd">            &gt;&gt;&gt; corpus.documents</span>
<span class="sd">            [&#39;so am i&#39;]</span>
<span class="sd">            &gt;&gt;&gt; sliced_data.documents</span>
<span class="sd">            [&#39;i am an example&#39;]</span>
<span class="sd">            &gt;&gt;&gt; corpus.most_common()</span>
<span class="sd">            [(&#39;am&#39;, 1), (&#39;i&#39;, 1), (&#39;so&#39;, 1)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_index</span> <span class="o">=</span> <span class="n">Corpus</span><span class="p">([])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_copy_standard</span><span class="p">(</span><span class="n">new_index</span><span class="p">)</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split_off</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_index</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">split_off</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
            <span class="n">new_index</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
        <span class="n">own_docs</span><span class="p">,</span> <span class="n">own_tokenized</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">documents</span><span class="p">,</span> <span class="n">tokenized_docs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="c1"># we have to match to the length of the documents because len(self)</span>
        <span class="c1"># is tied to the length of the index, which is smaller now</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indexes</span><span class="p">:</span>
                <span class="n">documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">tokenized_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">own_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">own_tokenized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">documents</span>
        <span class="n">new_index</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">=</span> <span class="n">tokenized_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">own_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">=</span> <span class="n">own_tokenized</span>
        <span class="k">return</span> <span class="n">new_index</span></div>

<div class="viewcode-block" id="Corpus.flatten"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.flatten">[docs]</a>    <span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordIndex</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Flattens a Corpus, converting it into a :class:`~text_data.index.WordIndex`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_index</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></div>

<div class="viewcode-block" id="Corpus.update"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;Adds new documents to the corpus&#39;s index and to the n-gram indices.</span>

<span class="sd">        Args:</span>
<span class="sd">            new_documents: A list of new documents. The tokenizer used is the same</span>
<span class="sd">                tokenizer used to initialize the corpus.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_documents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tokenized_docs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">new_documents</span><span class="p">]</span>
            <span class="c1"># for some reason mypy doesn&#39;t get that this converts from a list of tuples to a tuple of lists</span>
            <span class="n">words</span><span class="p">,</span> <span class="n">positions</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">tokenized_docs</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">words</span><span class="p">,</span> <span class="n">positions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">positions</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">+=</span> <span class="n">new_documents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span> <span class="o">+=</span> <span class="n">words</span>
        <span class="k">for</span> <span class="n">ngram</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngram_indexes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">ngram_tok</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">ngrams_from_documents</span><span class="p">(</span>
                <span class="n">words</span><span class="p">,</span>
                <span class="n">ngram</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ngram_sep</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ngram_prefix</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ngram_suffix</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">index</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">ngram_tok</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_yield_subquery_document_results</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">subquery</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">QueryItem</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Yields sets of documents given QueryItem objects.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">search_item</span> <span class="ow">in</span> <span class="n">subquery</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">search_item</span><span class="o">.</span><span class="n">exact</span><span class="p">:</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">find_documents_with_phrase</span><span class="p">(</span><span class="n">search_item</span><span class="o">.</span><span class="n">words</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">find_documents_with_words</span><span class="p">(</span><span class="n">search_item</span><span class="o">.</span><span class="n">words</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_yield_subquery_phrase_results</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">subquery</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">QueryItem</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="n">PositionResult</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Yields sets of positions in format of PositionResult.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">search_item</span> <span class="ow">in</span> <span class="n">subquery</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">search_item</span><span class="o">.</span><span class="n">exact</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">{</span>
                    <span class="n">PositionResult</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">find_phrase_positions</span><span class="p">(</span><span class="n">search_item</span><span class="o">.</span><span class="n">words</span><span class="p">)</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">{</span>
                    <span class="n">PositionResult</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">find_wordlist_positions</span><span class="p">(</span><span class="n">search_item</span><span class="o">.</span><span class="n">words</span><span class="p">)</span>
                <span class="p">}</span>

    <span class="k">def</span> <span class="nf">_search_item</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">yield_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
            <span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">QueryItem</span><span class="p">]],</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="n">SearchResult</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="p">],</span>
        <span class="n">query_instance</span><span class="p">:</span> <span class="n">Query</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">SearchResult</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Internal function for search_documents and search_occurrences.&quot;&quot;&quot;</span>
        <span class="n">query_results</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">query_docs</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">subquery</span> <span class="ow">in</span> <span class="n">query_instance</span><span class="o">.</span><span class="n">queries</span><span class="p">:</span>
            <span class="n">subquery_results</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">yield_function</span><span class="p">(</span><span class="n">subquery</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># we&#39;ll add *all* the positions to set</span>
            <span class="c1"># and only return the ones with the relevant docs</span>
            <span class="n">query_results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">subquery_results</span><span class="p">)</span>
            <span class="n">subquery_docs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">q</span><span class="o">.</span><span class="n">doc_id</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">PositionResult</span><span class="p">)</span> <span class="k">else</span> <span class="n">q</span>
                <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">subquery_results</span>
            <span class="p">}</span>
            <span class="n">modifier_type</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="o">.</span><span class="n">modifier</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">subquery</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">modifier_type</span> <span class="o">==</span> <span class="p">{</span><span class="s2">&quot;AND&quot;</span><span class="p">}:</span>
                <span class="n">query_docs</span><span class="o">.</span><span class="n">intersection_update</span><span class="p">(</span><span class="n">subquery_docs</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">modifier_type</span> <span class="o">==</span> <span class="p">{</span><span class="s2">&quot;OR&quot;</span><span class="p">}:</span>
                <span class="n">query_docs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">subquery_docs</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">modifier_type</span> <span class="o">==</span> <span class="p">{</span><span class="s2">&quot;NOT&quot;</span><span class="p">}:</span>
                <span class="n">query_docs</span> <span class="o">-=</span> <span class="n">subquery_docs</span>
        <span class="c1"># this tries to figure out the type of result we have</span>
        <span class="c1"># whether we&#39;re dealing with occurrence searches or document searches</span>
        <span class="k">if</span> <span class="nb">all</span><span class="p">((</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">PositionResult</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">subquery_results</span><span class="p">)):</span>
            <span class="c1"># need this check because set() passes the above check</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">subquery_results</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">{</span><span class="n">q</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">query_results</span> <span class="k">if</span> <span class="n">q</span><span class="o">.</span><span class="n">doc_id</span> <span class="ow">in</span> <span class="n">query_docs</span><span class="p">}</span>  <span class="c1"># type: ignore</span>
        <span class="k">return</span> <span class="n">query_docs</span>  <span class="c1"># type: ignore</span>

<div class="viewcode-block" id="Corpus.search_documents"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.search_documents">[docs]</a>    <span class="k">def</span> <span class="nf">search_documents</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Search documents from a query.</span>

<span class="sd">        In order to figure out the intracacies of writing queries,</span>
<span class="sd">        you should view :py:mod:`text_data.query.Query`. In general,</span>
<span class="sd">        standard boolean (AND, OR, NOT) searches work perfectly reasonably.</span>
<span class="sd">        You should generally not need to set :code:`query_tokenizer` to anything</span>
<span class="sd">        other than the default (string split).</span>

<span class="sd">        This produces a set of unique documents, where each document is</span>
<span class="sd">        the index of the document. To view the documents by their ranked importance</span>
<span class="sd">        (ranked largely using TF-IDF), use :meth:`~text_data.index.Corpus.ranked_search`.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;this is an example&quot;, &quot;here is another&quot;])</span>
<span class="sd">            &gt;&gt;&gt; assert corpus.search_documents(&quot;is&quot;) == {0, 1}</span>
<span class="sd">            &gt;&gt;&gt; assert corpus.search_documents(&quot;example&quot;) == {0}</span>

<span class="sd">        Args:</span>
<span class="sd">            query: A string boolean query (as defined in :class:`text_data.query.Query`)</span>
<span class="sd">            query_tokenizer: A function to tokenize the words in your query. This</span>
<span class="sd">                allows you to optionally search for words in your index that include</span>
<span class="sd">                spaces (since it defaults to string.split).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search_item</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_yield_subquery_document_results</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">Query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">),</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.search_occurrences"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.search_occurrences">[docs]</a>    <span class="k">def</span> <span class="nf">search_occurrences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">PositionResult</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Search for matching positions within a search.</span>

<span class="sd">        This allows you to figure out all of the occurrences</span>
<span class="sd">        matching your query. In addition, this is used internally</span>
<span class="sd">        to display search results.</span>

<span class="sd">        Each matching position comes in the form of a tuple where</span>
<span class="sd">        the first field :code:`doc_id` refers to the position</span>
<span class="sd">        of the document, the second field :code:`first_idx`</span>
<span class="sd">        refers to the starting index of the occurrence (among</span>
<span class="sd">        the tokenized documents), :code:`last_idx` refers to the</span>
<span class="sd">        last index of the occurrence, :code:`raw_start` refers</span>
<span class="sd">        to the starting index of the occurrence from</span>
<span class="sd">        *within the raw, non-tokenized documents.* :code:`raw_end`</span>
<span class="sd">        refers to the *index after the last character of the matching</span>
<span class="sd">        result* within the non-tokenized documents. There is not really</span>
<span class="sd">        a reason behind this decision.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;this is fun&quot;])</span>
<span class="sd">            &gt;&gt;&gt; result = list(corpus.search_occurrences(&quot;&#39;this is&#39;&quot;))[0]</span>
<span class="sd">            &gt;&gt;&gt; result</span>
<span class="sd">            PositionResult(doc_id=0, first_idx=0, last_idx=1, raw_start=0, raw_end=7)</span>
<span class="sd">            &gt;&gt;&gt; corpus.documents[result.doc_id][result.raw_start:result.raw_end]</span>
<span class="sd">            &#39;this is&#39;</span>
<span class="sd">            &gt;&gt;&gt; corpus.tokenized_documents[result.doc_id][result.first_idx:result.last_idx+1]</span>
<span class="sd">            [&#39;this&#39;, &#39;is&#39;]</span>

<span class="sd">        Args:</span>
<span class="sd">            query: The string query. See :class:`text_data.query.Query` for details.</span>
<span class="sd">            query_tokenizer: The tokenizing function for the query.</span>
<span class="sd">                See :class:`text_data.query.Query` or :meth:`~text_data.index.Corpus.search_documents`</span>
<span class="sd">                for details.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search_item</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_yield_subquery_phrase_results</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">Query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">),</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.ranked_search"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.ranked_search">[docs]</a>    <span class="k">def</span> <span class="nf">ranked_search</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">PositionResult</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;This produces a list of search responses in ranked order.</span>

<span class="sd">        More specifically, the documents are ranked in order of the</span>
<span class="sd">        sum of the TF-IDF scores for each word in the query</span>
<span class="sd">        (with the exception of words that are negated using a NOT operator).</span>

<span class="sd">        To compute the TF-IDF scores, I simply have computed the dot products</span>
<span class="sd">        between the raw query counts and the TF-IDF scores of all the unique</span>
<span class="sd">        words in the query. This is roughly equivalent to the :code:`ltn.lnn`</span>
<span class="sd">        normalization scheme</span>
<span class="sd">        `described in Manning &lt;https://nlp.stanford.edu/IR-book/html/htmledition/document-and-query-weighting-schemes-1.html&gt;`_.</span>
<span class="sd">        (The catch is that I have normalized the term-frequencies in the document</span>
<span class="sd">        to the length of the document.)</span>

<span class="sd">        Each item in the resulting list is a list referring to a single item.</span>
<span class="sd">        The items inside each of those lists are of the same format you get from</span>
<span class="sd">        :meth:`~text_data.index.Corpus.search_occurrences`. The first item in</span>
<span class="sd">        each list is either an item having the largest number of words in it</span>
<span class="sd">        or is the item that&#39;s the nearest to another match within the document.</span>

<span class="sd">        Args:</span>
<span class="sd">            query: Query string</span>
<span class="sd">            query_tokenizer: Function for tokenizing the results.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of tuples, each in the same format as :meth:`~text_data.index.Corpus.search_occurrences`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">query_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">Query</span><span class="p">(</span><span class="n">query_string</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">)</span>
        <span class="c1"># sorting the results allows grouping using itertools + allows linear distance calc</span>
        <span class="n">all_matches</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_search_item</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_yield_subquery_phrase_results</span><span class="p">,</span> <span class="n">query</span>  <span class="c1"># type: ignore</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># runs into divide by 0 error on idf computation without this being explicit</span>
        <span class="k">if</span> <span class="n">all_matches</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="c1"># create a list of words from the query where the word is not being excluded</span>
        <span class="n">query_tokens</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">word</span>
            <span class="k">for</span> <span class="n">subquery</span> <span class="ow">in</span> <span class="n">query</span><span class="o">.</span><span class="n">queries</span>
            <span class="k">for</span> <span class="n">q_item</span> <span class="ow">in</span> <span class="n">subquery</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">q_item</span><span class="o">.</span><span class="n">words</span>
            <span class="k">if</span> <span class="n">q_item</span><span class="o">.</span><span class="n">modifier</span> <span class="o">!=</span> <span class="s2">&quot;NOT&quot;</span>
        <span class="p">]</span>
        <span class="n">query_counts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">query_tokens</span><span class="p">)</span>
        <span class="n">query_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">query_counts</span><span class="p">)</span>
        <span class="n">query_freqs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">query_counts</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">query_words</span><span class="p">])</span>
        <span class="n">idf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">document_count</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">query_words</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">matches</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span>
            <span class="n">all_matches</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">doc_id</span>  <span class="c1"># type: ignore</span>
        <span class="p">):</span>
            <span class="n">term_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">term_count</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">query_words</span><span class="p">])</span>
            <span class="n">term_freqs</span> <span class="o">=</span> <span class="n">term_counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenized_documents</span><span class="p">[</span><span class="n">doc</span><span class="p">])</span>
            <span class="n">log_term_freqs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">term_freqs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">tfidf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">query_freqs</span><span class="p">,</span> <span class="n">log_term_freqs</span> <span class="o">*</span> <span class="n">idf</span><span class="p">)</span>
            <span class="n">position_match</span><span class="p">,</span> <span class="n">num_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sort_positions</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="n">query_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tfidf</span><span class="p">,</span> <span class="o">-</span><span class="n">num_dist</span><span class="p">,</span> <span class="n">position_match</span><span class="p">))</span>
        <span class="c1"># sort results by TF-IDF scores, followed by the smallest distance</span>
        <span class="c1"># followed by the document order</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">result</span> <span class="k">for</span> <span class="o">*</span><span class="n">sort_terms</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">query_results</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span></div>

    <span class="k">def</span> <span class="nf">_sort_positions</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">matches</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">PositionResult</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">PositionResult</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Chooses one positional match for a given document.</span>

<span class="sd">        Internal method for ranked positional search. Sorts by the longest</span>
<span class="sd">        phrase, followed by for the phrase that is closest to another phrase.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PositionResult</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">min_closest</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">prev_result</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
            <span class="n">item_length</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">last_idx</span> <span class="o">-</span> <span class="n">match</span><span class="o">.</span><span class="n">first_idx</span>
            <span class="k">if</span> <span class="n">prev_result</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dist_to_prev</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dist_to_prev</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">first_idx</span> <span class="o">-</span> <span class="n">prev_result</span><span class="o">.</span><span class="n">last_idx</span>
            <span class="c1"># first set the current match to the choice</span>
            <span class="c1"># if it is longer than remainders</span>
            <span class="k">if</span> <span class="n">max_len</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">item_length</span> <span class="o">&gt;</span> <span class="n">max_len</span><span class="p">:</span>
                <span class="n">max_len</span> <span class="o">=</span> <span class="n">item_length</span>
                <span class="n">results</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">match</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist_to_prev</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">min_closest</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">dist_to_prev</span> <span class="o">&lt;</span> <span class="n">min_closest</span><span class="p">:</span>
                    <span class="n">min_closest</span> <span class="o">=</span> <span class="n">dist_to_prev</span>
                    <span class="c1"># only change current result if the length of the phrase</span>
                    <span class="c1"># is not less than the max length</span>
                    <span class="k">if</span> <span class="n">item_length</span> <span class="o">==</span> <span class="n">max_len</span><span class="p">:</span>
                        <span class="n">results</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">match</span><span class="p">)</span>
            <span class="n">prev_result</span> <span class="o">=</span> <span class="n">match</span>
            <span class="c1"># don&#39;t insert twice</span>
            <span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">match</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">match</span><span class="p">)</span>
        <span class="c1"># this maps distance to a guaranteed number and favors words with multiple items</span>
        <span class="n">num_dist</span> <span class="o">=</span> <span class="n">min_closest</span> <span class="k">if</span> <span class="n">min_closest</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span>
        <span class="c1"># above technically returns an optional position, but it&#39;s</span>
        <span class="c1"># a private method that only runs when the position isn&#39;t none</span>
        <span class="k">return</span> <span class="n">results</span><span class="p">,</span> <span class="n">num_dist</span>  <span class="c1"># type: ignore</span>

<div class="viewcode-block" id="Corpus.display_search_results"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.display_search_results">[docs]</a>    <span class="k">def</span> <span class="nf">display_search_results</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">search_query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
        <span class="n">max_results</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">window_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Shows the results of a ranked query.</span>

<span class="sd">        This function runs a query and then renders the result in human-readable</span>
<span class="sd">        HTML. For each result, you will get a document ID and the count of the result.</span>

<span class="sd">        In addition, all of the matching occurrences of phrases or words you</span>
<span class="sd">        searched for will be highlighted in bold. You can optionally decide</span>
<span class="sd">        how many results you want to return and how long you want each result to be</span>
<span class="sd">        (up to the length of the whole document).</span>

<span class="sd">        Args:</span>
<span class="sd">            search_query: The query you&#39;re searching for</span>
<span class="sd">            query_tokenizer: The tokenizer for the query</span>
<span class="sd">            max_results: The maximum number of results. If None, returns all results.</span>
<span class="sd">            window_size: The number of characters you want to return around the matching phrase.</span>
<span class="sd">            If None, returns the entire document.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">html</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_show_html_occurrences</span><span class="p">(</span>
            <span class="n">search_query</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">,</span> <span class="n">max_results</span><span class="p">,</span> <span class="n">window_size</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">html</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_show_html_occurrences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">search_query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
        <span class="n">max_results</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">window_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Plots all of the search matches as HTML phrases.</span>

<span class="sd">        Each result contains information about the order in which it appeared,</span>
<span class="sd">        the document ID, and bolds each matching phrase. The results are centered</span>
<span class="sd">        around the match that appears to be closest based on _sort_positions.</span>

<span class="sd">        Returns the HTML and the number of documents returned.</span>

<span class="sd">        Args:</span>
<span class="sd">            search_query: The query you&#39;re searching for</span>
<span class="sd">            query_tokenizer: The tokenizer for the query</span>
<span class="sd">            max_results: The maximum number of results. If None, returns all results.</span>
<span class="sd">            window_size: The number of characters you want to return around the matching phrase.</span>
<span class="sd">            If None, returns the entire document.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">query_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranked_search</span><span class="p">(</span><span class="n">search_query</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">)</span>
        <span class="n">max_results</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">query_results</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_results</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">max_results</span>
        <span class="n">search_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranked_search</span><span class="p">(</span><span class="n">search_query</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">count</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">search_results</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="n">max_results</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">highlight_doc</span> <span class="o">=</span> <span class="n">doc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">results</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;&lt;p&gt;&lt;b&gt;Showing Result </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> (Document ID </span><span class="si">{</span><span class="n">highlight_doc</span><span class="o">.</span><span class="n">doc_id</span><span class="si">}</span><span class="s2">)&lt;/b&gt;&lt;/p&gt;&quot;</span>
                <span class="n">results</span> <span class="o">+=</span> <span class="s2">&quot;&lt;p style=&#39;white-space=pre-wrap;&#39;&gt;&quot;</span>
                <span class="n">sel_doc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">highlight_doc</span><span class="o">.</span><span class="n">doc_id</span><span class="p">]</span>
                <span class="c1"># replace the window size with the document size if it&#39;s set to None</span>
                <span class="n">doc_window</span> <span class="o">=</span> <span class="n">window_size</span> <span class="k">if</span> <span class="n">window_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">sel_doc</span><span class="p">)</span>
                <span class="c1"># we want to center the output around the best match in the document</span>
                <span class="n">start_window</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">highlight_doc</span><span class="o">.</span><span class="n">raw_start</span> <span class="o">-</span> <span class="n">doc_window</span><span class="p">)</span>
                <span class="n">end_window</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sel_doc</span><span class="p">),</span> <span class="n">highlight_doc</span><span class="o">.</span><span class="n">raw_end</span> <span class="o">+</span> <span class="n">doc_window</span><span class="p">)</span>
                <span class="n">current_idx</span> <span class="o">=</span> <span class="n">start_window</span>
                <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                    <span class="nb">filter</span><span class="p">(</span>
                        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">raw_end</span> <span class="o">&gt;=</span> <span class="n">start_window</span>
                        <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">raw_start</span> <span class="o">&lt;=</span> <span class="n">end_window</span><span class="p">,</span>
                        <span class="n">doc</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">):</span>
                    <span class="k">if</span> <span class="n">current_idx</span> <span class="o">==</span> <span class="n">start_window</span><span class="p">:</span>
                        <span class="n">actual_start</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                            <span class="n">highlight_doc</span><span class="o">.</span><span class="n">raw_start</span> <span class="o">-</span> <span class="n">doc_window</span><span class="p">,</span> <span class="n">item</span><span class="o">.</span><span class="n">raw_start</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="n">actual_start</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">results</span> <span class="o">+=</span> <span class="s2">&quot;&lt;b&gt;&amp;hellip;&lt;/b&gt;&quot;</span>
                    <span class="k">if</span> <span class="n">current_idx</span> <span class="o">&lt;</span> <span class="n">item</span><span class="o">.</span><span class="n">raw_start</span><span class="p">:</span>
                        <span class="n">results</span> <span class="o">+=</span> <span class="n">core</span><span class="o">.</span><span class="n">_escape_html</span><span class="p">(</span>
                            <span class="n">sel_doc</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">raw_start</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="n">block_text</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">_escape_html</span><span class="p">(</span>
                        <span class="n">sel_doc</span><span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">raw_start</span> <span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">raw_end</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="n">results</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;&lt;b&gt;</span><span class="si">{</span><span class="n">block_text</span><span class="si">}</span><span class="s2">&lt;/b&gt;&quot;</span>
                    <span class="n">current_idx</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">raw_end</span>
                <span class="n">raw_end_window</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">current_idx</span><span class="p">,</span> <span class="n">end_window</span><span class="p">)</span>
                <span class="n">results</span> <span class="o">+=</span> <span class="n">core</span><span class="o">.</span><span class="n">_escape_html</span><span class="p">(</span><span class="n">sel_doc</span><span class="p">[</span><span class="n">current_idx</span><span class="p">:</span><span class="n">raw_end_window</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">raw_end_window</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">sel_doc</span><span class="p">):</span>
                    <span class="n">results</span> <span class="o">+=</span> <span class="s2">&quot;&lt;b&gt;&amp;hellip;&lt;/b&gt;&quot;</span>
                <span class="n">results</span> <span class="o">+=</span> <span class="s2">&quot;&lt;/p&gt;&quot;</span>
        <span class="k">return</span> <span class="n">results</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">max_results</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">search_results</span><span class="p">))</span>

<div class="viewcode-block" id="Corpus.search_document_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.search_document_count">[docs]</a>    <span class="k">def</span> <span class="nf">search_document_count</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Finds the total number of documents matching a query.</span>

<span class="sd">        By entering a search, you can get the total number of documents</span>
<span class="sd">        that match the query.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;the cow was hungry&quot;, &quot;the cow likes the grass&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_document_count(&quot;cow&quot;)</span>
<span class="sd">            2</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_document_count(&quot;grass&quot;)</span>
<span class="sd">            1</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_document_count(&quot;the&quot;)</span>
<span class="sd">            2</span>

<span class="sd">        Args:</span>
<span class="sd">            query_string: The query you&#39;re searching for</span>
<span class="sd">            query_tokenizer: The tokenizer for the query</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">search_documents</span><span class="p">(</span><span class="n">query_string</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">))</span></div>

<div class="viewcode-block" id="Corpus.search_document_freq"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.search_document_freq">[docs]</a>    <span class="k">def</span> <span class="nf">search_document_freq</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Finds the percentage of documents that match a query.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;the cow was hungry&quot;, &quot;the cow likes the grass&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_document_freq(&quot;cow&quot;)</span>
<span class="sd">            1.0</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_document_freq(&quot;grass&quot;)</span>
<span class="sd">            0.5</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_document_freq(&quot;the grass&quot;)</span>
<span class="sd">            0.5</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_document_freq(&quot;the OR nonsense&quot;)</span>
<span class="sd">            1.0</span>

<span class="sd">        Args:</span>
<span class="sd">            query_string: The query you&#39;re searching for</span>
<span class="sd">            query_tokenizer: The tokenizer for the query</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">search_document_count</span><span class="p">(</span><span class="n">query_string</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.search_occurrence_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.search_occurrence_count">[docs]</a>    <span class="k">def</span> <span class="nf">search_occurrence_count</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Finds the total number of occurrences you have for the given query.</span>

<span class="sd">        This just gets the number of items in :meth:`~text_data.Corpus.search_occurrences`.</span>
<span class="sd">        As a result, searching for occurrences where two separate words occur will find</span>
<span class="sd">        the total number of places where either word occurs within the set of documents</span>
<span class="sd">        where both words appear.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; corpus = Corpus([&quot;the cow was hungry&quot;, &quot;the cow likes the grass&quot;])</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_occurrence_count(&quot;the&quot;)</span>
<span class="sd">            3</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_occurrence_count(&quot;the cow&quot;)</span>
<span class="sd">            5</span>
<span class="sd">            &gt;&gt;&gt; corpus.search_occurrence_count(&quot;&#39;the cow&#39;&quot;)</span>
<span class="sd">            2</span>

<span class="sd">        Args:</span>
<span class="sd">            query_string: The query you&#39;re searching for</span>
<span class="sd">            query_tokenizer: The tokenizer for the query</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">search_occurrences</span><span class="p">(</span><span class="n">query_string</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">))</span></div>

    <span class="nd">@core</span><span class="o">.</span><span class="n">requires_display_extra</span>
    <span class="k">def</span> <span class="nf">_render_bar_chart</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">metric_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
        <span class="n">metric_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">queries</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a bar chart given a callable that returns a metric.</span>

<span class="sd">        Internal for `display_document_count`, `display_document_freqs`, and `display_occurrence_count`.</span>

<span class="sd">        Args:</span>
<span class="sd">            metric_func: A function that takes in a query and returns a metric</span>
<span class="sd">                (e.g. `Corpus.search_document_count`)</span>
<span class="sd">            metric_name: The name for the metric (used as an axis label)</span>
<span class="sd">            queries: A list of queries</span>
<span class="sd">            query_tokenizer: A function for tokenizing the queries</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>

        <span class="n">json_data</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;Query&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">:</span> <span class="n">metric_func</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">query_tokenizer</span><span class="p">)}</span>
            <span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">queries</span>
        <span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">Data</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">json_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="o">.</span><span class="n">mark_bar</span><span class="p">()</span>
            <span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">:Q&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s2">&quot;Query:N&quot;</span><span class="p">,</span> <span class="n">sort</span><span class="o">=</span><span class="s2">&quot;-x&quot;</span><span class="p">))</span>
        <span class="p">)</span>

<div class="viewcode-block" id="Corpus.display_document_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.display_document_count">[docs]</a>    <span class="nd">@core</span><span class="o">.</span><span class="n">requires_display_extra</span>
    <span class="k">def</span> <span class="nf">display_document_count</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">queries</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a bar chart (in altair) showing the queries with the largest number of documents.</span>

<span class="sd">        Note:</span>
<span class="sd">            This method requires that you have :code:`altair` installed. To install,</span>
<span class="sd">            type :code:`pip install text_data[display]` or :code:`poetry add text_data -E display`.</span>

<span class="sd">        Args:</span>
<span class="sd">            queries: A list of queries (in the same form you use to search for things)</span>
<span class="sd">            query_tokenizer: The tokenizer for the query</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_render_bar_chart</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">search_document_count</span><span class="p">,</span> <span class="s2">&quot;Number of documents&quot;</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">query_tokenizer</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.display_document_frequency"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.display_document_frequency">[docs]</a>    <span class="nd">@core</span><span class="o">.</span><span class="n">requires_display_extra</span>
    <span class="k">def</span> <span class="nf">display_document_frequency</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">queries</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Displays a bar chart showing the percentages of documents with a given query.</span>

<span class="sd">        Note:</span>
<span class="sd">            This method requires that you have :code:`altair` installed. To install,</span>
<span class="sd">            type :code:`pip install text_data[display]` or :code:`poetry add text_data -E display`.</span>

<span class="sd">        Args:</span>
<span class="sd">            queries: A list of queries</span>
<span class="sd">            query_tokenizer: A tokenizer for each query</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_render_bar_chart</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">search_document_freq</span><span class="p">,</span> <span class="s2">&quot;Document Frequency&quot;</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">query_tokenizer</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Corpus.display_occurrence_count"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.display_occurrence_count">[docs]</a>    <span class="nd">@core</span><span class="o">.</span><span class="n">requires_display_extra</span>
    <span class="k">def</span> <span class="nf">display_occurrence_count</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">queries</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">query_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Display a bar chart showing the number of times a query matches.</span>

<span class="sd">        Note:</span>
<span class="sd">            This method requires that you have :code:`altair` installed. To install,</span>
<span class="sd">            type :code:`pip install text_data[display]` or :code:`poetry add text_data -E display`.</span>

<span class="sd">        Args:</span>
<span class="sd">            queries: A list of queries</span>
<span class="sd">            query_tokenizer: The tokenizer for the query</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_render_bar_chart</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">search_occurrence_count</span><span class="p">,</span> <span class="s2">&quot;Number of matches&quot;</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">query_tokenizer</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_document_html</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the HTML to display a document.</span>

<span class="sd">        Internal for `display_document` and `display_documents`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">_escape_html</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">doc_idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&lt;p&gt;&lt;b&gt;Document at index </span><span class="si">{</span><span class="n">doc_idx</span><span class="si">}</span><span class="s2">&lt;/b&gt;&lt;/p&gt;&lt;p&gt;</span><span class="si">{</span><span class="n">content</span><span class="si">}</span><span class="s2">&lt;/p&gt;&quot;</span>

<div class="viewcode-block" id="Corpus.display_document"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.display_document">[docs]</a>    <span class="k">def</span> <span class="nf">display_document</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Print an entire document, given its index.</span>

<span class="sd">        Args:</span>
<span class="sd">            doc_idx: The index of the document</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_document_html</span><span class="p">(</span><span class="n">doc_idx</span><span class="p">))</span></div>

<div class="viewcode-block" id="Corpus.display_documents"><a class="viewcode-back" href="../../text_data.html#text_data.index.Corpus.display_documents">[docs]</a>    <span class="k">def</span> <span class="nf">display_documents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Display a number of documents, at the specified indexes.</span>

<span class="sd">        Args:</span>
<span class="sd">            documents: A list of document indexes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">html</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_document_html</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">html</span><span class="p">)</span></div></div>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2020, Max Lee.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>